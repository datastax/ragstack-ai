= Examples

This section contains examples of how to use RAGStack.
We're actively updating this section, so check back often!

.RAGStack Examples
[options="header"]
|===
| Description | Colab | Documentation

| Perform multi-modal RAG with LangChain, AstraDB and a Google Gemini Pro Vision model.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/langchain_multimodal_gemini.ipynb"]
| xref:langchain_multimodal_gemini.adoc[]

| Build a simple RAG pipeline using
https://catalog.ngc.nvidia.com[NVIDIA AI Foundation Models]{external-link-icon}.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/nvidia.ipynb"]
| xref:nvidia_embeddings.adoc[]

| Build a hotels search application with RAGStack and AstraDB.
a| image::https://gitpod.io/button/open-in-gitpod.svg[align="left",110,link="https://gitpod.io/#https://github.com/hemidactylus/langchain-astrapy-hotels-app"]
| xref:hotels-app.adoc[]

| Vector search with the Maximal Marginal Relevance (MMR) algorithm.
image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/qa-maximal-marginal-relevance.ipynb"]
| xref:mmr.adoc[]

| Implement a generative Q&A over your own documentation with Astra Vector Search, OpenAI, and CassIO.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/QA_with_cassio.ipynb"]
| xref:qa-with-cassio.adoc[]

| Store external or proprietary data in Astra DB and query it to provide more up-to-date LLM responses.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/RAG_with_cassio.ipynb"]
| xref:rag-with-cassio.adoc[]

| Evaluate a RAG pipeline using LangChain's QA Evaluator.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/langchain_evaluation.ipynb"]
| xref:langchain-evaluation.adoc[]

| Evaluate the response accuracy, token cost, and responsiveness of MultiQueryRAG and ParentDocumentRAG.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/advancedRAG.ipynb"]
| xref:advanced-rag.adoc[]

| Orchestrate the advanced FLARE retrieval technique in a RAG pipeline.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/FLARE.ipynb"]
| xref:flare.adoc[]

| Build a simple RAG pipeline using LlamaIndex and AstraDB.
a| image::https://colab.research.google.com/assets/colab-badge.svg[align="left",link="https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/llama-astra.ipynb"]
| xref:llama-astra.adoc[]
|===


