= Store Embeddings

We recommend LangChain's `OpenAIEmbeddings` class for storing your embeddings in a vector store.

We recommend {company} {db-serverless} to store your embeddings. {db-serverless} integrates with LangChain as a vector store using the https://python.langchain.com/docs/integrations/vectorstores/astradb[AstraPy client].

include::examples:partial$prerequisites.adoc[]

== Store embeddings in the vector-enabled {db-serverless} database

This code embeds the loaded `Documents` from the xref:splitting.adoc[] example and stores the embeddings in the {db-serverless} vector store.
[source,python]
----
import os
from dotenv import load_dotenv
from langchain_astradb import AstraDBVectorStore
from langchain_openai import OpenAIEmbeddings

load_dotenv()

ASTRA_DB_COLLECTION = os.environ.get("ASTRA_DB_COLLECTION")

embedding = OpenAIEmbeddings()
vstore = AstraDBVectorStore(
    embedding=embedding,
    collection_name="test",
    token=os.environ["ASTRA_DB_APPLICATION_TOKEN"],
    api_endpoint=os.environ["ASTRA_DB_API_ENDPOINT"],
)
docs = []
inserted_ids = vstore.add_documents(docs)
print(f"\nInserted {len(inserted_ids)} documents.")

print(vstore.astra_db.collection(ASTRA_DB_COLLECTION).find())
----
