= Storing

We recommend LangChain's OpenAIEmbeddings class for storing your embeddings in a vector store.

We recommend DataStax {db-vector} to store your embeddings. It's a managed service that uses Cassandra under the hood, and is a good choice if you're already using Cassandra or want to use Cassandra for other parts of your application. {db-vector} integrates with LangChain as a vector store using the https://python.langchain.com/docs/integrations/vectorstores/astradb[Astrapy client].

include::examples:partial$prerequisites.adoc[]

== Store embeddings

This code embeds the loaded `Documents` from the xref:splitting.adoc[] example and stores the embeddings in the AstraDB vector store.
[source,python]
----
import os
from dotenv import load_dotenv
from langchain.vectorstores.astradb import AstraDB
from langchain.embeddings import OpenAIEmbeddings

load_dotenv()

ASTRA_DB_APPLICATION_TOKEN = os.environ.get("ASTRA_DB_APPLICATION_TOKEN")
ASTRA_DB_API_ENDPOINT = os.environ.get("ASTRA_DB_API_ENDPOINT")
OPEN_AI_API_KEY = os.environ.get("OPENAI_API_KEY")
ASTRA_DB_COLLECTION = os.environ.get("ASTRA_DB_COLLECTION")

embedding = OpenAIEmbeddings()
vstore = AstraDB(
    embedding=embedding,
    collection_name="test",
    token=os.environ["ASTRA_DB_APPLICATION_TOKEN"],
    api_endpoint=os.environ["ASTRA_DB_API_ENDPOINT"],
)
docs = []
inserted_ids = vstore.add_documents(docs)
print(f"\nInserted {len(inserted_ids)} documents.")

print(vstore.astra_db.collection(ASTRA_DB_COLLECTION).find())
----
