

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>langchain_community.vectorstores.deeplake &mdash; ðŸ¦œðŸ”— LangChain 0.1.4</title>
  
  <link rel="canonical" href="https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/deeplake.html" />

  

  <link rel="stylesheet" href="../../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/autodoc_pydantic.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script> 
</head>
<body>


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../../langchain_api_reference.html">LangChain</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../../core_api_reference.html">Core</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../../community_api_reference.html">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../../experimental_api_reference.html">Experimental</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../robocorp_api_reference.html">robocorp</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../openai_api_reference.html">openai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../together_api_reference.html">together</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../google_genai_api_reference.html">google-genai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../nvidia_ai_endpoints_api_reference.html">nvidia-ai-endpoints</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../google_vertexai_api_reference.html">google-vertexai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../anthropic_api_reference.html">anthropic</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../exa_api_reference.html">exa</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../mistralai_api_reference.html">mistralai</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../../nvidia_trt_api_reference.html">nvidia-trt</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Partner libs</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../robocorp_api_reference.html">robocorp</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../openai_api_reference.html">openai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../together_api_reference.html">together</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../google_genai_api_reference.html">google-genai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../nvidia_ai_endpoints_api_reference.html">nvidia-ai-endpoints</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../google_vertexai_api_reference.html">google-vertexai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../anthropic_api_reference.html">anthropic</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../exa_api_reference.html">exa</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../mistralai_api_reference.html">mistralai</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../../nvidia_trt_api_reference.html">nvidia-trt</a>
          </div>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://python.langchain.com/">Docs</a>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Prev</a><a href="../../index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Module code">Up</a>
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Next</a>
        </div>
            <div class="sk-sidebar-toc">
              
            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <h1>Source code for langchain_community.vectorstores.deeplake</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">deeplake</span>
    <span class="kn">from</span> <span class="nn">deeplake</span> <span class="kn">import</span> <span class="n">VectorStore</span> <span class="k">as</span> <span class="n">DeepLakeVectorStore</span>
    <span class="kn">from</span> <span class="nn">deeplake.core.fast_forwarding</span> <span class="kn">import</span> <span class="n">version_compare</span>

    <span class="n">_DEEPLAKE_INSTALLED</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">_DEEPLAKE_INSTALLED</span> <span class="o">=</span> <span class="kc">False</span>

<span class="kn">from</span> <span class="nn">langchain_core.documents</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">langchain_core.embeddings</span> <span class="kn">import</span> <span class="n">Embeddings</span>
<span class="kn">from</span> <span class="nn">langchain_core.vectorstores</span> <span class="kn">import</span> <span class="n">VectorStore</span>

<span class="kn">from</span> <span class="nn">langchain_community.vectorstores.utils</span> <span class="kn">import</span> <span class="n">maximal_marginal_relevance</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="DeepLake"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake">[docs]</a><span class="k">class</span> <span class="nc">DeepLake</span><span class="p">(</span><span class="n">VectorStore</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;`Activeloop Deep Lake` vector store.</span>

<span class="sd">    We integrated deeplake&#39;s similarity search and filtering for fast prototyping.</span>
<span class="sd">    Now, it supports Tensor Query Language (TQL) for production use cases</span>
<span class="sd">    over billion rows.</span>

<span class="sd">    Why Deep Lake?</span>

<span class="sd">    - Not only stores embeddings, but also the original data with version control.</span>
<span class="sd">    - Serverless, doesn&#39;t require another service and can be used with major</span>
<span class="sd">        cloud providers (S3, GCS, etc.)</span>
<span class="sd">    - More than just a multi-modal vector store. You can use the dataset</span>
<span class="sd">        to fine-tune your own LLM models.</span>

<span class="sd">    To use, you should have the ``deeplake`` python package installed.</span>

<span class="sd">    Example:</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">                from langchain_community.vectorstores import DeepLake</span>
<span class="sd">                from langchain_community.embeddings.openai import OpenAIEmbeddings</span>

<span class="sd">                embeddings = OpenAIEmbeddings()</span>
<span class="sd">                vectorstore = DeepLake(&quot;langchain_store&quot;, embeddings.embed_query)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_LANGCHAIN_DEFAULT_DEEPLAKE_PATH</span> <span class="o">=</span> <span class="s2">&quot;./deeplake/&quot;</span>

<div class="viewcode-block" id="DeepLake.__init__"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_LANGCHAIN_DEFAULT_DEEPLAKE_PATH</span><span class="p">,</span>
        <span class="n">token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">read_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">ingestion_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">runtime</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">index_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates an empty DeepLakeVectorStore or loads an existing one.</span>

<span class="sd">        The DeepLakeVectorStore is located at the specified ``path``.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Create a vector store with default tensors</span>
<span class="sd">            &gt;&gt;&gt; deeplake_vectorstore = DeepLake(</span>
<span class="sd">            ...        path = &lt;path_for_storing_Data&gt;,</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create a vector store in the Deep Lake Managed Tensor Database</span>
<span class="sd">            &gt;&gt;&gt; data = DeepLake(</span>
<span class="sd">            ...        path = &quot;hub://org_id/dataset_name&quot;,</span>
<span class="sd">            ...        runtime = {&quot;tensor_db&quot;: True},</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_path (str): Path to existing dataset or where to create</span>
<span class="sd">                a new one. Defaults to _LANGCHAIN_DEFAULT_DEEPLAKE_PATH.</span>
<span class="sd">            token (str, optional):  Activeloop token, for fetching credentials</span>
<span class="sd">                to the dataset at path if it is a Deep Lake dataset.</span>
<span class="sd">                Tokens are normally autogenerated. Optional.</span>
<span class="sd">            embedding (Embeddings, optional): Function to convert</span>
<span class="sd">                either documents or query. Optional.</span>
<span class="sd">            embedding_function (Embeddings, optional): Function to convert</span>
<span class="sd">                either documents or query. Optional. Deprecated: keeping this</span>
<span class="sd">                parameter for backwards compatibility.</span>
<span class="sd">            read_only (bool): Open dataset in read-only mode. Default is False.</span>
<span class="sd">            ingestion_batch_size (int): During data ingestion, data is divided</span>
<span class="sd">                into batches. Batch size is the size of each batch.</span>
<span class="sd">                Default is 1000.</span>
<span class="sd">            num_workers (int): Number of workers to use during data ingestion.</span>
<span class="sd">                Default is 0.</span>
<span class="sd">            verbose (bool): Print dataset summary after each operation.</span>
<span class="sd">                Default is True.</span>
<span class="sd">            exec_option (str, optional): DeepLakeVectorStore supports 3 ways to perform</span>
<span class="sd">                searching - &quot;python&quot;, &quot;compute_engine&quot;, &quot;tensor_db&quot; and auto.</span>
<span class="sd">                Default is None.</span>
<span class="sd">                - ``auto``- Selects the best execution method based on the storage</span>
<span class="sd">                    location of the Vector Store. It is the default option.</span>
<span class="sd">                - ``python`` - Pure-python implementation that runs on the client.</span>
<span class="sd">                    WARNING: using this with big datasets can lead to memory</span>
<span class="sd">                    issues. Data can be stored anywhere.</span>
<span class="sd">                - ``compute_engine`` - C++ implementation of the Deep Lake Compute</span>
<span class="sd">                    Engine that runs on the client. Can be used for any data stored in</span>
<span class="sd">                    or connected to Deep Lake. Not for in-memory or local datasets.</span>
<span class="sd">                - ``tensor_db`` - Hosted Managed Tensor Database that is</span>
<span class="sd">                    responsible for storage and query execution. Only for data stored in</span>
<span class="sd">                    the Deep Lake Managed Database. Use runtime = {&quot;db_engine&quot;: True}</span>
<span class="sd">                    during dataset creation.</span>
<span class="sd">            runtime (Dict, optional): Parameters for creating the Vector Store in</span>
<span class="sd">                Deep Lake&#39;s Managed Tensor Database. Not applicable when loading an</span>
<span class="sd">                existing Vector Store. To create a Vector Store in the Managed Tensor</span>
<span class="sd">                Database, set `runtime = {&quot;tensor_db&quot;: True}`.</span>
<span class="sd">            index_params (Optional[Dict[str, Union[int, str]]], optional): Dictionary</span>
<span class="sd">                containing information about vector index that will be created. Defaults</span>
<span class="sd">                to None, which will utilize ``DEFAULT_VECTORSTORE_INDEX_PARAMS`` from</span>
<span class="sd">                ``deeplake.constants``. The specified key-values override the default</span>
<span class="sd">                ones.</span>
<span class="sd">                - threshold: The threshold for the dataset size above which an index</span>
<span class="sd">                    will be created for the embedding tensor. When the threshold value</span>
<span class="sd">                    is set to -1, index creation is turned off. Defaults to -1, which</span>
<span class="sd">                    turns off the index.</span>
<span class="sd">                - distance_metric: This key specifies the method of calculating the</span>
<span class="sd">                    distance between vectors when creating the vector database (VDB)</span>
<span class="sd">                    index. It can either be a string that corresponds to a member of</span>
<span class="sd">                    the DistanceType enumeration, or the string value itself.</span>
<span class="sd">                    - If no value is provided, it defaults to &quot;L2&quot;.</span>
<span class="sd">                    - &quot;L2&quot; corresponds to DistanceType.L2_NORM.</span>
<span class="sd">                    - &quot;COS&quot; corresponds to DistanceType.COSINE_SIMILARITY.</span>
<span class="sd">                - additional_params: Additional parameters for fine-tuning the index.</span>
<span class="sd">            **kwargs: Other optional keyword arguments.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If some condition is not met.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ingestion_batch_size</span> <span class="o">=</span> <span class="n">ingestion_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="k">if</span> <span class="n">_DEEPLAKE_INSTALLED</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import deeplake python package. &quot;</span>
                <span class="s2">&quot;Please install it with `pip install deeplake[enterprise]`.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="n">runtime</span> <span class="o">==</span> <span class="p">{</span><span class="s2">&quot;tensor_db&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>
            <span class="ow">and</span> <span class="n">version_compare</span><span class="p">(</span><span class="n">deeplake</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="s2">&quot;3.6.7&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
                <span class="s2">&quot;To use tensor_db option you need to update deeplake to `3.6.7` or &quot;</span>
                <span class="s2">&quot;higher. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Currently installed deeplake version is </span><span class="si">{</span><span class="n">deeplake</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_path</span> <span class="o">=</span> <span class="n">dataset_path</span>

        <span class="k">if</span> <span class="n">embedding_function</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Using embedding function is deprecated and will be removed &quot;</span>
                <span class="s2">&quot;in the future. Please use embedding instead.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span> <span class="o">=</span> <span class="n">DeepLakeVectorStore</span><span class="p">(</span>
            <span class="n">path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_path</span><span class="p">,</span>
            <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span> <span class="ow">or</span> <span class="n">embedding</span><span class="p">,</span>
            <span class="n">read_only</span><span class="o">=</span><span class="n">read_only</span><span class="p">,</span>
            <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">runtime</span><span class="o">=</span><span class="n">runtime</span><span class="p">,</span>
            <span class="n">index_params</span><span class="o">=</span><span class="n">index_params</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span> <span class="o">=</span> <span class="n">embedding_function</span> <span class="ow">or</span> <span class="n">embedding</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_id_tensor_name</span> <span class="o">=</span> <span class="s2">&quot;ids&quot;</span> <span class="k">if</span> <span class="s2">&quot;ids&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">tensors</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;id&quot;</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span>

<div class="viewcode-block" id="DeepLake.add_texts"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.add_texts">[docs]</a>    <span class="k">def</span> <span class="nf">add_texts</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">metadatas</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run more texts through the embeddings and add to the vectorstore.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; ids = deeplake_vectorstore.add_texts(</span>
<span class="sd">            ...     texts = &lt;list_of_texts&gt;,</span>
<span class="sd">            ...     metadatas = &lt;list_of_metadata_jsons&gt;,</span>
<span class="sd">            ...     ids = &lt;list_of_ids&gt;,</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            texts (Iterable[str]): Texts to add to the vectorstore.</span>
<span class="sd">            metadatas (Optional[List[dict]], optional): Optional list of metadatas.</span>
<span class="sd">            ids (Optional[List[str]], optional): Optional list of IDs.</span>
<span class="sd">            embedding_function (Optional[Embeddings], optional): Embedding function</span>
<span class="sd">                to use to convert the text into embeddings.</span>
<span class="sd">            **kwargs (Any): Any additional keyword arguments passed is not supported</span>
<span class="sd">                by this method.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[str]: List of IDs of the added texts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">unsupported_items</span> <span class="o">=</span> <span class="s2">&quot;`, `&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">unsupported_items</span><span class="si">}</span><span class="s2">` is/are not a valid argument to add_text method&quot;</span>
            <span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id_tensor_name</span> <span class="o">==</span> <span class="s2">&quot;ids&quot;</span><span class="p">:</span>  <span class="c1"># for backwards compatibility</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ids</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ids</span>

        <span class="k">if</span> <span class="n">metadatas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">metadatas</span> <span class="o">=</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">texts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`texts` parameter shouldn&#39;t be None.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`texts` parameter shouldn&#39;t be empty.&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
            <span class="n">text</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
            <span class="n">metadata</span><span class="o">=</span><span class="n">metadatas</span><span class="p">,</span>
            <span class="n">embedding_data</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
            <span class="n">embedding_tensor</span><span class="o">=</span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
            <span class="n">embedding_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">return_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_search_tql</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tql</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Function for performing tql_search.</span>

<span class="sd">        Args:</span>
<span class="sd">            tql (str): TQL Query string for direct evaluation.</span>
<span class="sd">                Available only for `compute_engine` and `tensor_db`.</span>
<span class="sd">            exec_option (str, optional): Supports 3 ways to search.</span>
<span class="sd">                Could be &quot;python&quot;, &quot;compute_engine&quot; or &quot;tensor_db&quot;. Default is &quot;python&quot;.</span>
<span class="sd">                - ``python`` - Pure-python implementation for the client.</span>
<span class="sd">                    WARNING: not recommended for big datasets due to potential memory</span>
<span class="sd">                    issues.</span>
<span class="sd">                - ``compute_engine`` - C++ implementation of Deep Lake Compute</span>
<span class="sd">                    Engine for the client. Not for in-memory or local datasets.</span>
<span class="sd">                - ``tensor_db`` - Hosted Managed Tensor Database for storage</span>
<span class="sd">                    and query execution. Only for data in Deep Lake Managed Database.</span>
<span class="sd">                        Use runtime = {&quot;db_engine&quot;: True} during dataset creation.</span>
<span class="sd">            return_score (bool): Return score with document. Default is False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[List[Document], List[Tuple[Document, float]]] - A tuple of two lists.</span>
<span class="sd">                The first list contains Documents, and the second list contains</span>
<span class="sd">                tuples of Document and float score.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If return_score is True but some condition is not met.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">tql</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">metadatas</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;metadata&quot;</span><span class="p">]</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>

        <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Document</span><span class="p">(</span>
                <span class="n">page_content</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">metadatas</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">unsupported_argument</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">kwargs</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">unsupported_argument</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;specifying </span><span class="si">{</span><span class="n">unsupported_argument</span><span class="si">}</span><span class="s2"> is &quot;</span>
                    <span class="s2">&quot;not supported with tql search.&quot;</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">docs</span>

    <span class="k">def</span> <span class="nf">_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">embedding_function</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">distance_metric</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_maximal_marginal_relevance</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">fetch_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="nb">filter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_score</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">deep_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Document</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return docs similar to query.</span>

<span class="sd">        Args:</span>
<span class="sd">            query (str, optional): Text to look up similar docs.</span>
<span class="sd">            embedding (Union[List[float], np.ndarray], optional): Query&#39;s embedding.</span>
<span class="sd">            embedding_function (Callable, optional): Function to convert `query`</span>
<span class="sd">                into embedding.</span>
<span class="sd">            k (int): Number of Documents to return.</span>
<span class="sd">            distance_metric (Optional[str], optional): `L2` for Euclidean, `L1` for</span>
<span class="sd">                Nuclear, `max` for L-infinity distance, `cos` for cosine similarity,</span>
<span class="sd">                &#39;dot&#39; for dot product.</span>
<span class="sd">            filter (Union[Dict, Callable], optional): Additional filter prior</span>
<span class="sd">                to the embedding search.</span>
<span class="sd">                - ``Dict`` - Key-value search on tensors of htype json, on an</span>
<span class="sd">                    AND basis (a sample must satisfy all key-value filters to be True)</span>
<span class="sd">                    Dict = {&quot;tensor_name_1&quot;: {&quot;key&quot;: value},</span>
<span class="sd">                            &quot;tensor_name_2&quot;: {&quot;key&quot;: value}}</span>
<span class="sd">                - ``Function`` - Any function compatible with `deeplake.filter`.</span>
<span class="sd">            use_maximal_marginal_relevance (bool): Use maximal marginal relevance.</span>
<span class="sd">            fetch_k (int): Number of Documents for MMR algorithm.</span>
<span class="sd">            return_score (bool): Return the score.</span>
<span class="sd">            exec_option (str, optional): Supports 3 ways to perform searching.</span>
<span class="sd">                Could be &quot;python&quot;, &quot;compute_engine&quot; or &quot;tensor_db&quot;.</span>
<span class="sd">                - ``python`` - Pure-python implementation for the client.</span>
<span class="sd">                    WARNING: not recommended for big datasets.</span>
<span class="sd">                - ``compute_engine`` - C++ implementation of Deep Lake Compute</span>
<span class="sd">                    Engine for the client. Not for in-memory or local datasets.</span>
<span class="sd">                - ``tensor_db`` - Hosted Managed Tensor Database for storage</span>
<span class="sd">                    and query execution. Only for data in Deep Lake Managed Database.</span>
<span class="sd">                    Use runtime = {&quot;db_engine&quot;: True} during dataset creation.</span>
<span class="sd">            deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                search results. Defaults to False if deep_memory is not specified in</span>
<span class="sd">                the Vector Store initialization. If True, the distance metric is set</span>
<span class="sd">                to &quot;deepmemory_distance&quot;, which represents the metric with which the</span>
<span class="sd">                model was trained. The search is performed using the Deep Memory model.</span>
<span class="sd">                If False, the distance metric is set to &quot;COS&quot; or whatever distance</span>
<span class="sd">                metric user specifies.</span>
<span class="sd">            **kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of Documents by the specified distance metric,</span>
<span class="sd">            if return_score True, return a tuple of (Document, score)</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if both `embedding` and `embedding_function` are not specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;tql&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search_tql</span><span class="p">(</span>
                <span class="n">tql</span><span class="o">=</span><span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;tql&quot;</span><span class="p">],</span>
                <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
                <span class="n">return_score</span><span class="o">=</span><span class="n">return_score</span><span class="p">,</span>
                <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
                <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span><span class="p">,</span>
                <span class="n">distance_metric</span><span class="o">=</span><span class="n">distance_metric</span><span class="p">,</span>
                <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="n">use_maximal_marginal_relevance</span><span class="p">,</span>
                <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">embedding_function</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embedding_function</span><span class="p">,</span> <span class="n">Embeddings</span><span class="p">):</span>
                <span class="n">_embedding_function</span> <span class="o">=</span> <span class="n">embedding_function</span><span class="o">.</span><span class="n">embed_query</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_embedding_function</span> <span class="o">=</span> <span class="n">embedding_function</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span><span class="p">:</span>
            <span class="n">_embedding_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span><span class="o">.</span><span class="n">embed_query</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_embedding_function</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">embedding</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_embedding_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Either `embedding` or `embedding_function` needs to be&quot;</span>
                    <span class="s2">&quot; specified.&quot;</span>
                <span class="p">)</span>

            <span class="n">embedding</span> <span class="o">=</span> <span class="n">_embedding_function</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="k">if</span> <span class="n">query</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embedding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">embedding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">embedding</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">search</span><span class="p">(</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">fetch_k</span> <span class="k">if</span> <span class="n">use_maximal_marginal_relevance</span> <span class="k">else</span> <span class="n">k</span><span class="p">,</span>
            <span class="n">distance_metric</span><span class="o">=</span><span class="n">distance_metric</span><span class="p">,</span>
            <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span> <span class="s2">&quot;metadata&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_id_tensor_name</span><span class="p">],</span>
            <span class="n">deep_memory</span><span class="o">=</span><span class="n">deep_memory</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;embedding&quot;</span><span class="p">]</span>
        <span class="n">metadatas</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;metadata&quot;</span><span class="p">]</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">use_maximal_marginal_relevance</span><span class="p">:</span>
            <span class="n">lambda_mult</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;lambda_mult&quot;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">maximal_marginal_relevance</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
                <span class="n">embedding</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
                <span class="n">embeddings</span><span class="p">,</span>
                <span class="n">k</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">)),</span>
                <span class="n">lambda_mult</span><span class="o">=</span><span class="n">lambda_mult</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
            <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
            <span class="n">metadatas</span> <span class="o">=</span> <span class="p">[</span><span class="n">metadatas</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>

        <span class="n">docs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Document</span><span class="p">(</span>
                <span class="n">page_content</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">metadata</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">metadatas</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">return_score</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[(</span><span class="n">doc</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">scores</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">docs</span>

<div class="viewcode-block" id="DeepLake.similarity_search"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.similarity_search">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return docs most similar to query.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">            &gt;&gt;&gt; data = vector_store.similarity_search(</span>
<span class="sd">            ...     query=&lt;your_query&gt;,</span>
<span class="sd">            ...     k=&lt;num_items&gt;,</span>
<span class="sd">            ...     exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; # Run tql search:</span>
<span class="sd">            &gt;&gt;&gt; data = vector_store.similarity_search(</span>
<span class="sd">            ...     query=None,</span>
<span class="sd">            ...     tql=&quot;SELECT * WHERE id == &lt;id&gt;&quot;,</span>
<span class="sd">            ...     exec_option=&quot;compute_engine&quot;,</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            k (int): Number of Documents to return. Defaults to 4.</span>
<span class="sd">            query (str): Text to look up similar documents.</span>
<span class="sd">            **kwargs: Additional keyword arguments include:</span>
<span class="sd">                embedding (Callable): Embedding function to use. Defaults to None.</span>
<span class="sd">                distance_metric (str): &#39;L2&#39; for Euclidean, &#39;L1&#39; for Nuclear, &#39;max&#39;</span>
<span class="sd">                    for L-infinity, &#39;cos&#39; for cosine, &#39;dot&#39; for dot product.</span>
<span class="sd">                    Defaults to &#39;L2&#39;.</span>
<span class="sd">                filter (Union[Dict, Callable], optional): Additional filter</span>
<span class="sd">                    before embedding search.</span>
<span class="sd">                    - Dict: Key-value search on tensors of htype json,</span>
<span class="sd">                        (sample must satisfy all key-value filters)</span>
<span class="sd">                        Dict = {&quot;tensor_1&quot;: {&quot;key&quot;: value}, &quot;tensor_2&quot;: {&quot;key&quot;: value}}</span>
<span class="sd">                    - Function: Compatible with `deeplake.filter`.</span>
<span class="sd">                    Defaults to None.</span>
<span class="sd">                exec_option (str): Supports 3 ways to perform searching.</span>
<span class="sd">                    &#39;python&#39;, &#39;compute_engine&#39;, or &#39;tensor_db&#39;. Defaults to &#39;python&#39;.</span>
<span class="sd">                    - &#39;python&#39;: Pure-python implementation for the client.</span>
<span class="sd">                        WARNING: not recommended for big datasets.</span>
<span class="sd">                    - &#39;compute_engine&#39;: C++ implementation of the Compute Engine for</span>
<span class="sd">                        the client. Not for in-memory or local datasets.</span>
<span class="sd">                    - &#39;tensor_db&#39;: Managed Tensor Database for storage and query.</span>
<span class="sd">                        Only for data in Deep Lake Managed Database.</span>
<span class="sd">                        Use `runtime = {&quot;db_engine&quot;: True}` during dataset creation.</span>
<span class="sd">                deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                    search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                    in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                    is set to &quot;deepmemory_distance&quot;, which represents the metric with</span>
<span class="sd">                    which the model was trained. The search is performed using the Deep</span>
<span class="sd">                    Memory model. If False, the distance metric is set to &quot;COS&quot; or</span>
<span class="sd">                    whatever distance metric user specifies.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Document]: List of Documents most similar to the query vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">return_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.similarity_search_by_vector"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.similarity_search_by_vector">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_search_by_vector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return docs most similar to embedding vector.</span>

<span class="sd">        Examples:</span>
<span class="sd">            &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">            &gt;&gt;&gt; data = vector_store.similarity_search_by_vector(</span>
<span class="sd">            ...    embedding=&lt;your_embedding&gt;,</span>
<span class="sd">            ...    k=&lt;num_items_to_return&gt;,</span>
<span class="sd">            ...    exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">            ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding (Union[List[float], np.ndarray]):</span>
<span class="sd">                Embedding to find similar docs.</span>
<span class="sd">            k (int): Number of Documents to return. Defaults to 4.</span>
<span class="sd">            **kwargs: Additional keyword arguments including:</span>
<span class="sd">                filter (Union[Dict, Callable], optional):</span>
<span class="sd">                    Additional filter before embedding search.</span>
<span class="sd">                    - ``Dict`` - Key-value search on tensors of htype json. True</span>
<span class="sd">                        if all key-value filters are satisfied.</span>
<span class="sd">                        Dict = {&quot;tensor_name_1&quot;: {&quot;key&quot;: value},</span>
<span class="sd">                                &quot;tensor_name_2&quot;: {&quot;key&quot;: value}}</span>
<span class="sd">                    - ``Function`` - Any function compatible with</span>
<span class="sd">                        `deeplake.filter`.</span>
<span class="sd">                    Defaults to None.</span>
<span class="sd">                exec_option (str): Options for search execution include</span>
<span class="sd">                    &quot;python&quot;, &quot;compute_engine&quot;, or &quot;tensor_db&quot;. Defaults to</span>
<span class="sd">                    &quot;python&quot;.</span>
<span class="sd">                    - &quot;python&quot; - Pure-python implementation running on the client.</span>
<span class="sd">                        Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                        option with big datasets is discouraged due to potential</span>
<span class="sd">                        memory issues.</span>
<span class="sd">                    - &quot;compute_engine&quot; - Performant C++ implementation of the Deep</span>
<span class="sd">                        Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                        any data stored in or connected to Deep Lake. It cannot be</span>
<span class="sd">                        used with in-memory or local datasets.</span>
<span class="sd">                    - &quot;tensor_db&quot; - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                        Responsible for storage and query execution. Only available</span>
<span class="sd">                        for data stored in the Deep Lake Managed Database.</span>
<span class="sd">                        To store datasets in this database, specify</span>
<span class="sd">                        `runtime = {&quot;db_engine&quot;: True}` during dataset creation.</span>
<span class="sd">                distance_metric (str): `L2` for Euclidean, `L1` for Nuclear,</span>
<span class="sd">                    `max` for L-infinity distance, `cos` for cosine similarity,</span>
<span class="sd">                    &#39;dot&#39; for dot product. Defaults to `L2`.</span>
<span class="sd">                deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                    search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                    in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                    is set to &quot;deepmemory_distance&quot;, which represents the metric with</span>
<span class="sd">                    which the model was trained. The search is performed using the Deep</span>
<span class="sd">                    Memory model. If False, the distance metric is set to &quot;COS&quot; or</span>
<span class="sd">                    whatever distance metric user specifies.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Document]: List of Documents most similar to the query vector.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">return_score</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.similarity_search_with_score"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.similarity_search_with_score">[docs]</a>    <span class="k">def</span> <span class="nf">similarity_search_with_score</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Document</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run similarity search with Deep Lake with distance returned.</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; data = vector_store.similarity_search_with_score(</span>
<span class="sd">        ...     query=&lt;your_query&gt;,</span>
<span class="sd">        ...     embedding=&lt;your_embedding_function&gt;</span>
<span class="sd">        ...     k=&lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...     exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            query (str): Query text to search for.</span>
<span class="sd">            k (int): Number of results to return. Defaults to 4.</span>
<span class="sd">            **kwargs: Additional keyword arguments. Some of these arguments are:</span>
<span class="sd">                distance_metric: `L2` for Euclidean, `L1` for Nuclear, `max` L-infinity</span>
<span class="sd">                    distance, `cos` for cosine similarity, &#39;dot&#39; for dot product.</span>
<span class="sd">                    Defaults to `L2`.</span>
<span class="sd">                filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.</span>
<span class="sd">                    embedding_function (Callable): Embedding function to use. Defaults</span>
<span class="sd">                    to None.</span>
<span class="sd">                exec_option (str): DeepLakeVectorStore supports 3 ways to perform</span>
<span class="sd">                    searching. It could be either &quot;python&quot;, &quot;compute_engine&quot; or</span>
<span class="sd">                    &quot;tensor_db&quot;. Defaults to &quot;python&quot;.</span>
<span class="sd">                    - &quot;python&quot; - Pure-python implementation running on the client.</span>
<span class="sd">                        Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                        option with big datasets is discouraged due to potential</span>
<span class="sd">                        memory issues.</span>
<span class="sd">                    - &quot;compute_engine&quot; - Performant C++ implementation of the Deep</span>
<span class="sd">                        Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                        any data stored in or connected to Deep Lake. It cannot be used</span>
<span class="sd">                        with in-memory or local datasets.</span>
<span class="sd">                    - &quot;tensor_db&quot; - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                        Responsible for storage and query execution. Only available for</span>
<span class="sd">                        data stored in the Deep Lake Managed Database. To store datasets</span>
<span class="sd">                        in this database, specify `runtime = {&quot;db_engine&quot;: True}`</span>
<span class="sd">                        during dataset creation.</span>
<span class="sd">                deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                    search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                    in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                    is set to &quot;deepmemory_distance&quot;, which represents the metric with</span>
<span class="sd">                    which the model was trained. The search is performed using the Deep</span>
<span class="sd">                    Memory model. If False, the distance metric is set to &quot;COS&quot; or</span>
<span class="sd">                    whatever distance metric user specifies.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Tuple[Document, float]]: List of documents most similar to the query</span>
<span class="sd">                text with distance in float.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">return_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.max_marginal_relevance_search_by_vector"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.max_marginal_relevance_search_by_vector">[docs]</a>    <span class="k">def</span> <span class="nf">max_marginal_relevance_search_by_vector</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">fetch_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">lambda_mult</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return docs selected using the maximal marginal relevance. Maximal marginal</span>
<span class="sd">        relevance optimizes for similarity to query AND diversity among selected docs.</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; data = vector_store.max_marginal_relevance_search_by_vector(</span>
<span class="sd">        ...        embedding=&lt;your_embedding&gt;,</span>
<span class="sd">        ...        fetch_k=&lt;elements_to_fetch_before_mmr_search&gt;,</span>
<span class="sd">        ...        k=&lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...        exec_option=&lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            embedding: Embedding to look up documents similar to.</span>
<span class="sd">            k: Number of Documents to return. Defaults to 4.</span>
<span class="sd">            fetch_k: Number of Documents to fetch for MMR algorithm.</span>
<span class="sd">            lambda_mult: Number between 0 and 1 determining the degree of diversity.</span>
<span class="sd">                0 corresponds to max diversity and 1 to min diversity. Defaults to 0.5.</span>
<span class="sd">            exec_option (str): DeepLakeVectorStore supports 3 ways for searching.</span>
<span class="sd">                Could be &quot;python&quot;, &quot;compute_engine&quot; or &quot;tensor_db&quot;. Defaults to</span>
<span class="sd">                &quot;python&quot;.</span>
<span class="sd">                - &quot;python&quot; - Pure-python implementation running on the client.</span>
<span class="sd">                    Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                    option with big datasets is discouraged due to potential</span>
<span class="sd">                    memory issues.</span>
<span class="sd">                - &quot;compute_engine&quot; - Performant C++ implementation of the Deep</span>
<span class="sd">                    Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                    any data stored in or connected to Deep Lake. It cannot be used</span>
<span class="sd">                    with in-memory or local datasets.</span>
<span class="sd">                - &quot;tensor_db&quot; - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                    Responsible for storage and query execution. Only available for</span>
<span class="sd">                    data stored in the Deep Lake Managed Database. To store datasets</span>
<span class="sd">                    in this database, specify `runtime = {&quot;db_engine&quot;: True}`</span>
<span class="sd">                    during dataset creation.</span>
<span class="sd">            deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                is set to &quot;deepmemory_distance&quot;, which represents the metric with</span>
<span class="sd">                which the model was trained. The search is performed using the Deep</span>
<span class="sd">                Memory model. If False, the distance metric is set to &quot;COS&quot; or</span>
<span class="sd">                whatever distance metric user specifies.</span>
<span class="sd">            **kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List[Documents] - A list of documents.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">fetch_k</span><span class="o">=</span><span class="n">fetch_k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">lambda_mult</span><span class="o">=</span><span class="n">lambda_mult</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.max_marginal_relevance_search"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.max_marginal_relevance_search">[docs]</a>    <span class="k">def</span> <span class="nf">max_marginal_relevance_search</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">fetch_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">lambda_mult</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">exec_option</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return docs selected using maximal marginal relevance.</span>

<span class="sd">        Maximal marginal relevance optimizes for similarity to query AND diversity</span>
<span class="sd">        among selected documents.</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">        &gt;&gt;&gt; data = vector_store.max_marginal_relevance_search(</span>
<span class="sd">        ...        query = &lt;query_to_search&gt;,</span>
<span class="sd">        ...        embedding_function = &lt;embedding_function_for_query&gt;,</span>
<span class="sd">        ...        k = &lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...        exec_option = &lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            query: Text to look up documents similar to.</span>
<span class="sd">            k: Number of Documents to return. Defaults to 4.</span>
<span class="sd">            fetch_k: Number of Documents for MMR algorithm.</span>
<span class="sd">            lambda_mult: Value between 0 and 1. 0 corresponds</span>
<span class="sd">                        to maximum diversity and 1 to minimum.</span>
<span class="sd">                        Defaults to 0.5.</span>
<span class="sd">            exec_option (str): Supports 3 ways to perform searching.</span>
<span class="sd">                - &quot;python&quot; - Pure-python implementation running on the client.</span>
<span class="sd">                        Can be used for data stored anywhere. WARNING: using this</span>
<span class="sd">                        option with big datasets is discouraged due to potential</span>
<span class="sd">                        memory issues.</span>
<span class="sd">                    - &quot;compute_engine&quot; - Performant C++ implementation of the Deep</span>
<span class="sd">                        Lake Compute Engine. Runs on the client and can be used for</span>
<span class="sd">                        any data stored in or connected to Deep Lake. It cannot be</span>
<span class="sd">                        used with in-memory or local datasets.</span>
<span class="sd">                    - &quot;tensor_db&quot; - Performant, fully-hosted Managed Tensor Database.</span>
<span class="sd">                        Responsible for storage and query execution. Only available</span>
<span class="sd">                        for data stored in the Deep Lake Managed Database. To store</span>
<span class="sd">                        datasets in this database, specify</span>
<span class="sd">                        `runtime = {&quot;db_engine&quot;: True}` during dataset creation.</span>
<span class="sd">            deep_memory (bool): Whether to use the Deep Memory model for improving</span>
<span class="sd">                search results. Defaults to False if deep_memory is not specified</span>
<span class="sd">                in the Vector Store initialization. If True, the distance metric</span>
<span class="sd">                is set to &quot;deepmemory_distance&quot;, which represents the metric with</span>
<span class="sd">                which the model was trained. The search is performed using the Deep</span>
<span class="sd">                Memory model. If False, the distance metric is set to &quot;COS&quot; or</span>
<span class="sd">                whatever distance metric user specifies.</span>
<span class="sd">            **kwargs: Additional keyword arguments</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of Documents selected by maximal marginal relevance.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: when MRR search is on but embedding function is</span>
<span class="sd">                not specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">embedding_function</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;embedding&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_function</span>
        <span class="k">if</span> <span class="n">embedding_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;For MMR search, you must specify an embedding function on&quot;</span>
                <span class="s2">&quot; `creation` or during add call.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_search</span><span class="p">(</span>
            <span class="n">query</span><span class="o">=</span><span class="n">query</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
            <span class="n">fetch_k</span><span class="o">=</span><span class="n">fetch_k</span><span class="p">,</span>
            <span class="n">use_maximal_marginal_relevance</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">lambda_mult</span><span class="o">=</span><span class="n">lambda_mult</span><span class="p">,</span>
            <span class="n">exec_option</span><span class="o">=</span><span class="n">exec_option</span><span class="p">,</span>
            <span class="n">embedding_function</span><span class="o">=</span><span class="n">embedding_function</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.from_texts"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.from_texts">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_texts</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Embeddings</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">metadatas</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">dict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dataset_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">_LANGCHAIN_DEFAULT_DEEPLAKE_PATH</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DeepLake</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a Deep Lake dataset from a raw documents.</span>

<span class="sd">        If a dataset_path is specified, the dataset will be persisted in that location,</span>
<span class="sd">        otherwise by default at `./deeplake`</span>

<span class="sd">        Examples:</span>
<span class="sd">        &gt;&gt;&gt; # Search using an embedding</span>
<span class="sd">        &gt;&gt;&gt; vector_store = DeepLake.from_texts(</span>
<span class="sd">        ...        texts = &lt;the_texts_that_you_want_to_embed&gt;,</span>
<span class="sd">        ...        embedding_function = &lt;embedding_function_for_query&gt;,</span>
<span class="sd">        ...        k = &lt;number_of_items_to_return&gt;,</span>
<span class="sd">        ...        exec_option = &lt;preferred_exec_option&gt;,</span>
<span class="sd">        ... )</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset_path (str): - The full path to the dataset. Can be:</span>
<span class="sd">                - Deep Lake cloud path of the form ``hub://username/dataset_name``.</span>
<span class="sd">                    To write to Deep Lake cloud datasets,</span>
<span class="sd">                    ensure that you are logged in to Deep Lake</span>
<span class="sd">                    (use &#39;activeloop login&#39; from command line)</span>
<span class="sd">                - AWS S3 path of the form ``s3://bucketname/path/to/dataset``.</span>
<span class="sd">                    Credentials are required in either the environment</span>
<span class="sd">                - Google Cloud Storage path of the form</span>
<span class="sd">                    ``gcs://bucketname/path/to/dataset`` Credentials are required</span>
<span class="sd">                    in either the environment</span>
<span class="sd">                - Local file system path of the form ``./path/to/dataset`` or</span>
<span class="sd">                    ``~/path/to/dataset`` or ``path/to/dataset``.</span>
<span class="sd">                - In-memory path of the form ``mem://path/to/dataset`` which doesn&#39;t</span>
<span class="sd">                    save the dataset, but keeps it in memory instead.</span>
<span class="sd">                    Should be used only for testing as it does not persist.</span>
<span class="sd">            texts (List[Document]): List of documents to add.</span>
<span class="sd">            embedding (Optional[Embeddings]): Embedding function. Defaults to None.</span>
<span class="sd">                Note, in other places, it is called embedding_function.</span>
<span class="sd">            metadatas (Optional[List[dict]]): List of metadatas. Defaults to None.</span>
<span class="sd">            ids (Optional[List[str]]): List of document IDs. Defaults to None.</span>
<span class="sd">            **kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            DeepLake: Deep Lake dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">deeplake_dataset</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">dataset_path</span><span class="o">=</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">deeplake_dataset</span><span class="o">.</span><span class="n">add_texts</span><span class="p">(</span>
            <span class="n">texts</span><span class="o">=</span><span class="n">texts</span><span class="p">,</span>
            <span class="n">metadatas</span><span class="o">=</span><span class="n">metadatas</span><span class="p">,</span>
            <span class="n">ids</span><span class="o">=</span><span class="n">ids</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">deeplake_dataset</span></div>

<div class="viewcode-block" id="DeepLake.delete"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.delete">[docs]</a>    <span class="k">def</span> <span class="nf">delete</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Delete the entities in the dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            ids (Optional[List[str]], optional): The document_ids to delete.</span>
<span class="sd">                Defaults to None.</span>
<span class="sd">            **kwargs: Other keyword arguments that subclasses might use.</span>
<span class="sd">                - filter (Optional[Dict[str, str]], optional): The filter to delete by.</span>
<span class="sd">                - delete_all (Optional[bool], optional): Whether to drop the dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: Whether the delete operation was successful.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">filter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;filter&quot;</span><span class="p">)</span>
        <span class="n">delete_all</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;delete_all&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">ids</span><span class="o">=</span><span class="n">ids</span><span class="p">,</span> <span class="nb">filter</span><span class="o">=</span><span class="nb">filter</span><span class="p">,</span> <span class="n">delete_all</span><span class="o">=</span><span class="n">delete_all</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="DeepLake.force_delete_by_path"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.force_delete_by_path">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">force_delete_by_path</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Force delete dataset by path.</span>

<span class="sd">        Args:</span>
<span class="sd">            path (str): path of the dataset to delete.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: if deeplake is not installed.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">deeplake</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Could not import deeplake python package. &quot;</span>
                <span class="s2">&quot;Please install it with `pip install deeplake`.&quot;</span>
            <span class="p">)</span>
        <span class="n">deeplake</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">large_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.delete_dataset"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.delete_dataset">[docs]</a>    <span class="k">def</span> <span class="nf">delete_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Delete the collection.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">delete_all</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>

<div class="viewcode-block" id="DeepLake.ds"><a class="viewcode-back" href="../../../vectorstores/langchain_community.vectorstores.deeplake.DeepLake.html#langchain_community.vectorstores.deeplake.DeepLake.ds">[docs]</a>    <span class="k">def</span> <span class="nf">ds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;this method is deprecated and will be removed, &quot;</span>
            <span class="s2">&quot;better to use `db.vectorstore.dataset` instead.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">dataset</span></div></div>
</pre></div>

      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2023, LangChain, Inc..
          Last updated on Feb 13, 2024.
      </footer>
    </div>
  </div>
</div>
<script src="../../../_static/js/vendor/bootstrap.min.js"></script>
<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">Â¶</a>');
	});
});

</script>
    
</body>
</html>