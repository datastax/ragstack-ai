

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>langchain.chains.structured_output.base.create_structured_output_runnable &mdash; 🦜🔗 LangChain 0.1.12</title>
  
  <link rel="canonical" href="https://api.python.langchain.com/en/latest/chains/langchain.chains.structured_output.base.create_structured_output_runnable.html" />

  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/autodoc_pydantic.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>


<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../langchain_api_reference.html">LangChain</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../core_api_reference.html">Core</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../community_api_reference.html">Community</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../experimental_api_reference.html">Experimental</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../text_splitters_api_reference.html">Text splitters</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Partner libs</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
          </div>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" target="_blank" rel="noopener noreferrer" href="https://python.langchain.com/">Docs</a>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Go" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Toggle Menu</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Prev</a>
            <a href="#" role="button" class="btn sk-btn-rellink disabled py-1">Up</a>
            <a href="#" role="button" class="btn sk-btn-rellink py-1 disabled"">Next</a>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain.chains.structured_output.base</span></code>.create_structured_output_runnable</a><ul>
<li><a class="reference internal" href="#langchain.chains.structured_output.base.create_structured_output_runnable"><code class="docutils literal notranslate"><span class="pre">create_structured_output_runnable()</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="langchain-chains-structured-output-base-create-structured-output-runnable">
<h1><code class="xref py py-mod docutils literal notranslate"><span class="pre">langchain.chains.structured_output.base</span></code>.create_structured_output_runnable<a class="headerlink" href="#langchain-chains-structured-output-base-create-structured-output-runnable" title="Permalink to this heading">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="langchain.chains.structured_output.base.create_structured_output_runnable">
<span class="sig-prename descclassname"><span class="pre">langchain.chains.structured_output.base.</span></span><span class="sig-name descname"><span class="pre">create_structured_output_runnable</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output_schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">BaseModel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">llm</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">prompt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../prompts/langchain_core.prompts.base.BasePromptTemplate.html#langchain_core.prompts.base.BasePromptTemplate" title="langchain_core.prompts.base.BasePromptTemplate"><span class="pre">BasePromptTemplate</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_parser</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="../output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html#langchain_core.output_parsers.base.BaseOutputParser" title="langchain_core.output_parsers.base.BaseOutputParser"><span class="pre">BaseOutputParser</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="../output_parsers/langchain_core.output_parsers.base.BaseGenerationOutputParser.html#langchain_core.output_parsers.base.BaseGenerationOutputParser" title="langchain_core.output_parsers.base.BaseGenerationOutputParser"><span class="pre">BaseGenerationOutputParser</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enforce_function_usage</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_single</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'openai-functions'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'openai-tools'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'openai-json'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'openai-functions'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><span class="pre">Runnable</span></a></span></span><a class="reference internal" href="../_modules/langchain/chains/structured_output/base.html#create_structured_output_runnable"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#langchain.chains.structured_output.base.create_structured_output_runnable" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a runnable for extracting structured outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_schema</strong> (<em>Union</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Type</em><em>[</em><em>BaseModel</em><em>]</em><em>]</em>) – Either a dictionary or pydantic.BaseModel class. If a dictionary
is passed in, it’s assumed to already be a valid JsonSchema.
For best results, pydantic.BaseModels should have docstrings describing what
the schema represents and descriptions for the parameters.</p></li>
<li><p><strong>llm</strong> (<a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a>) – Language model to use. Assumed to support the OpenAI function-calling API
if mode is ‘openai-function’. Assumed to support OpenAI response_format
parameter if mode is ‘openai-json’.</p></li>
<li><p><strong>prompt</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="../prompts/langchain_core.prompts.base.BasePromptTemplate.html#langchain_core.prompts.base.BasePromptTemplate" title="langchain_core.prompts.base.BasePromptTemplate"><em>BasePromptTemplate</em></a><em>]</em>) – BasePromptTemplate to pass to the model. If mode is ‘openai-json’ and
prompt has input variable ‘output_schema’ then the given output_schema
will be converted to a JsonSchema and inserted in the prompt.</p></li>
<li><p><strong>output_parser</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference internal" href="../output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html#langchain_core.output_parsers.base.BaseOutputParser" title="langchain_core.output_parsers.base.BaseOutputParser"><em>BaseOutputParser</em></a><em>, </em><a class="reference internal" href="../output_parsers/langchain_core.output_parsers.base.BaseGenerationOutputParser.html#langchain_core.output_parsers.base.BaseGenerationOutputParser" title="langchain_core.output_parsers.base.BaseGenerationOutputParser"><em>BaseGenerationOutputParser</em></a><em>]</em><em>]</em>) – Output parser to use for parsing model outputs. By default
will be inferred from the function types. If pydantic.BaseModel is passed
in, then the OutputParser will try to parse outputs using the pydantic
class. Otherwise model outputs will be parsed as JSON.</p></li>
<li><p><strong>mode</strong> (<em>Literal</em><em>[</em><em>'openai-functions'</em><em>, </em><em>'openai-tools'</em><em>, </em><em>'openai-json'</em><em>]</em>) – How structured outputs are extracted from the model. If ‘openai-functions’
then OpenAI function calling is used with the deprecated ‘functions’,
‘function_call’ schema. If ‘openai-tools’ then OpenAI function
calling with the latest ‘tools’, ‘tool_choice’ schema is used. This is
recommended over ‘openai-functions’. If ‘openai-json’ then OpenAI model
with response_format set to JSON is used.</p></li>
<li><p><strong>enforce_function_usage</strong> (<em>bool</em>) – Only applies when mode is ‘openai-tools’ or
‘openai-functions’. If True, then the model will be forced to use the given
output schema. If False, then the model can elect whether to use the output
schema.</p></li>
<li><p><strong>return_single</strong> (<em>bool</em>) – Only applies when mode is ‘openai-tools’. Whether to a list of
structured outputs or a single one. If True and model does not return any
structured outputs then chain output is None. If False and model does not
return any structured outputs then chain output is an empty list.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – Additional named arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>A runnable sequence that will return a structured output(s) matching the given</dt><dd><p>output_schema.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="../runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable" title="langchain_core.runnables.base.Runnable"><em>Runnable</em></a></p>
</dd>
</dl>
<dl>
<dt>OpenAI tools example with Pydantic schema (mode=’openai-tools’):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>


<span class="k">class</span> <span class="nc">RecordDog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Record some identifying information about a dog.&#39;&#39;&#39;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s name&quot;</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s color&quot;</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s favorite food&quot;</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;You are an extraction algorithm. Please extract every possible instance&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;human&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{input}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span>
    <span class="n">RecordDog</span><span class="p">,</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;openai-tools&quot;</span><span class="p">,</span>
    <span class="n">enforce_function_usage</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_single</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Harry was a chubby brown beagle who loved chicken&quot;</span><span class="p">})</span>
<span class="c1"># -&gt; RecordDog(name=&quot;Harry&quot;, color=&quot;brown&quot;, fav_food=&quot;chicken&quot;)</span>
</pre></div>
</div>
</dd>
<dt>OpenAI tools example with dict schema (mode=”openai-tools”):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>


<span class="n">dog_schema</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;function&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;record_dog&quot;</span><span class="p">,</span>
        <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;Record some identifying information about a dog.&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;object&quot;</span><span class="p">,</span>
            <span class="s2">&quot;properties&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The dog&#39;s name&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span>
                <span class="p">},</span>
                <span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The dog&#39;s color&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span>
                <span class="p">},</span>
                <span class="s2">&quot;fav_food&quot;</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">&quot;description&quot;</span><span class="p">:</span> <span class="s2">&quot;The dog&#39;s favorite food&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;string&quot;</span>
                <span class="p">}</span>
            <span class="p">},</span>
            <span class="s2">&quot;required&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="s2">&quot;color&quot;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>


<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span>
    <span class="n">doc_schema</span><span class="p">,</span>
    <span class="n">llm</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;openai-tools&quot;</span><span class="p">,</span>
    <span class="n">enforce_function_usage</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_single</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Harry was a chubby brown beagle who loved chicken&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; {&#39;name&#39;: &#39;Harry&#39;, &#39;color&#39;: &#39;brown&#39;, &#39;fav_food&#39;: &#39;chicken&#39;}</span>
</pre></div>
</div>
</dd>
<dt>OpenAI functions example (mode=”openai-functions”):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Identifying information about a dog.&#39;&#39;&#39;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s name&quot;</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s color&quot;</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s favorite food&quot;</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span><span class="n">Dog</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;openai-functions&quot;</span><span class="p">)</span>
<span class="n">structured_llm</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Harry was a chubby brown beagle who loved chicken&quot;</span><span class="p">)</span>
<span class="c1"># -&gt; Dog(name=&quot;Harry&quot;, color=&quot;brown&quot;, fav_food=&quot;chicken&quot;)</span>
</pre></div>
</div>
</dd>
<dt>OpenAI functions with prompt example:</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Identifying information about a dog.&#39;&#39;&#39;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s name&quot;</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s color&quot;</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s favorite food&quot;</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span><span class="n">Dog</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;openai-functions&quot;</span><span class="p">)</span>
<span class="n">system</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Extract information about any dogs mentioned in the user input.&#39;&#39;&#39;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="n">system</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">),]</span>
<span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">structured_llm</span>
<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Harry was a chubby brown beagle who loved chicken&quot;</span><span class="p">})</span>
<span class="c1"># -&gt; Dog(name=&quot;Harry&quot;, color=&quot;brown&quot;, fav_food=&quot;chicken&quot;)</span>
</pre></div>
</div>
</dd>
<dt>OpenAI json response format example (mode=”openai-json”):</dt><dd><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">create_structured_output_runnable</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_core.pydantic_v1</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>

<span class="k">class</span> <span class="nc">Dog</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Identifying information about a dog.&#39;&#39;&#39;</span>

    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s name&quot;</span><span class="p">)</span>
    <span class="n">color</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s color&quot;</span><span class="p">)</span>
    <span class="n">fav_food</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The dog&#39;s favorite food&quot;</span><span class="p">)</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">structured_llm</span> <span class="o">=</span> <span class="n">create_structured_output_runnable</span><span class="p">(</span><span class="n">Dog</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;openai-json&quot;</span><span class="p">)</span>
<span class="n">system</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;You are a world class assistant for extracting information in structured JSON formats.</span>
<span class="s1">Extract a valid JSON blob from the user input that matches the following JSON Schema:</span>

<span class="si">{output_schema}</span><span class="s1">&#39;&#39;&#39;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">(</span>
    <span class="p">[(</span><span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="n">system</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{input}</span><span class="s2">&quot;</span><span class="p">),]</span>
<span class="p">)</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">structured_llm</span>
<span class="n">chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Harry was a chubby brown beagle who loved chicken&quot;</span><span class="p">})</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<ul class="simple">
</ul>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2023, LangChain, Inc..
          Last updated on Mar 15, 2024.
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>
<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
});

</script>
    
</body>
</html>