{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Unstructured with LangChain & AstraDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show a basic RAG-style example that uses the Unstructured API to parse a PDF document, store the corresponding document into a vector store (`AstraDB`) and finally, perform some basic queries against that store. The notebook is modeled after the quick start notebooks and hence is meant as a way of getting started with Unstructured, backed by a vector database.\n",
    "\n",
    "To use Unstructured, you need an API key. Sign-up for one here: https://unstructured.io/api-key-hosted. A key will be emailed to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:48:33.967092Z",
     "start_time": "2024-02-13T11:47:41.568768Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, install the required dependencies\n",
    "! pip install --quiet ragstack-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:59:43.987486Z",
     "start_time": "2024-02-13T11:56:57.909870Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"UNSTRUCTURED_API_KEY\"] = getpass(\"Enter your Unstructured API Key:\")\n",
    "os.environ[\"UNSTRUCTURED_API_URL\"] = getpass(\"Enter your Unstructured API URL:\")\n",
    "os.environ[\"ASTRA_DB_ENDPOINT\"] = input(\"Enter your Astra DB API Endpoint: \")\n",
    "os.environ[\"ASTRA_DB_TOKEN\"] = getpass(\"Enter your Astra DB Token: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Unstructured API to parse a PDF\n",
    "\n",
    "In this example notebook, we'll focus our analysis on pages 9 and 10 of the referenced paper, available at https://arxiv.org/pdf/1706.03762.pdf, to limit API usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Parsing\n",
    "\n",
    "First we will start with the most basic parsing mode. This works well if your document doesn't contain any complex formatting or tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:05:20.215552Z",
     "start_time": "2024-02-13T12:05:15.721697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredAPIFileLoader\n",
    "import os\n",
    "\n",
    "loader = UnstructuredAPIFileLoader(\n",
    "    file_path=\"./resources/attention_pages_9_10.pdf\",\n",
    "    api_key=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    "    url = os.getenv(\"UNSTRUCTURED_API_URL\"),\n",
    ")\n",
    "simple_docs = loader.load()\n",
    "len(simple_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the parser returns 1 document per pdf file.  Lets examine some the contents of the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base model. All metrics are on the English-to-German translation development set, newstest2013. Listed perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to per-word perplexities.\n",
      "\n",
      "base\n",
      "\n",
      "(A)\n",
      "\n",
      "(B)\n",
      "\n",
      "(C)\n",
      "\n",
      "(D)\n",
      "\n",
      "N dmodel\n",
      "\n",
      "6\n",
      "\n",
      "512\n",
      "\n",
      "2 4 8\n",
      "\n",
      "256 1024\n",
      "\n",
      "dff\n",
      "\n",
      "2048\n",
      "\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "print(simple_docs[0].page_content[0:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample of the document contents shows the first table's description, and the start of a very poorly formatted table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Parsing\n",
    "\n",
    "By changing the processing strategy and response mode, we can get more detailed document structure. Unstructured can break the document into elements of different types, which can be helpful for improving your RAG system.\n",
    "\n",
    "For example, the `Table` element type includes the table formatted as simple html, which can help the LLM answer questions from the table data, and we could exclude elements of type `Footer` from our vector store.\n",
    "\n",
    "A list of all the different element types can be found here: https://unstructured-io.github.io/unstructured/introduction/overview.html#id1\n",
    "\n",
    "Returned metadata can also be helpful. For example, the `page_number` of the pdf input, and a `parent_id` property which helps define nesting of text sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import unstructured\n",
    "\n",
    "elements = unstructured.get_elements_from_api(\n",
    "    file_path=\"./resources/attention_pages_9_10.pdf\",\n",
    "    api_key=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    "    api_url = os.getenv(\"UNSTRUCTURED_API_URL\"),\n",
    "    strategy=\"hi_res\", # default \"auto\"\n",
    "    pdf_infer_table_structure=True,\n",
    ")\n",
    "\n",
    "len(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a single document returned from the pdf, we now have 27 elements. Below, we use element type and `parent_id` to show a clearer representation of the document structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base model. All metrics are on the English-to-German translation development set, newstest2013. Listed perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to per-word perplexities.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead><th></th><th>N</th><th>dwss</th><th>dn</th><th>b</th><th>di</th><th>Pug</th><th>as</th><th>gon</th><th>| 08</th><th>BORT</th><th>PR</th></thead><tr><td>base</td><td>| 6</td><td>512</td><td>2048</td><td>8</td><td>64</td><td>0.1</td><td>01</td><td>100K</td><td>| 492</td><td>258</td><td>65</td></tr><tr><td></td><td></td><td></td><td></td><td>1</td><td>512</td><td></td><td></td><td></td><td>529</td><td>249</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>4</td><td>128</td><td></td><td></td><td></td><td>500</td><td>255</td><td></td></tr><tr><td>(A)</td><td></td><td></td><td></td><td>16</td><td>32</td><td></td><td></td><td></td><td>491</td><td>258</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td>32</td><td>16</td><td></td><td></td><td></td><td>501</td><td>254</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td>16</td><td></td><td></td><td></td><td>516</td><td>251</td><td>58</td></tr><tr><td>®)</td><td></td><td></td><td></td><td></td><td>32</td><td></td><td></td><td></td><td>501</td><td>254</td><td>60</td></tr><tr><td rowspan=\"7\">©)</td><td>2</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>6.11</td><td>237</td><td>36</td></tr><tr><td></td><td>4</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>519</td><td>253</td><td>50</td></tr><tr><td></td><td>8</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>488</td><td>255</td><td>80</td></tr><tr><td></td><td></td><td>256</td><td></td><td></td><td>32</td><td></td><td></td><td></td><td>575</td><td>245</td><td>28</td></tr><tr><td></td><td></td><td>1024</td><td></td><td></td><td>128</td><td></td><td></td><td></td><td>4.66</td><td>26.0</td><td>168</td></tr><tr><td></td><td></td><td></td><td>1024</td><td></td><td></td><td></td><td></td><td></td><td>512</td><td>254</td><td>53</td></tr><tr><td></td><td></td><td></td><td>4096</td><td></td><td></td><td></td><td></td><td></td><td>475</td><td>262</td><td>90</td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>0.0</td><td></td><td></td><td>577</td><td>246</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>0.2</td><td></td><td></td><td>495</td><td>255</td><td></td></tr><tr><td>D</td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.0</td><td></td><td>461</td><td>253</td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.2</td><td></td><td>547</td><td>257</td><td></td></tr><tr><td>(E)</td><td></td><td></td><td>positional</td><td>embedding</td><td>instead</td><td>of sinusoids</td><td></td><td></td><td>4.92</td><td>25.7</td><td></td></tr><tr><td>big</td><td>| 6</td><td>1024</td><td>4096</td><td>16</td><td></td><td>0.3</td><td></td><td>300K</td><td>| 433</td><td>264</td><td>213</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "development set, newstest2013. We used beam search as described in the previous section, but no checkpoint averaging. We present these results in Table 3.\n",
      "In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions, keeping the amount of computation constant, as described in Section 3.2.2. While single-head attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\n",
      "In Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This suggests that determining compatibility is not easy and that a more sophisticated compatibility function than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected, bigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our sinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical results to the base model.\n",
      "6.3 English Constituency Parsing\n",
      "parent: '6.3 English Constituency Parsing' content: To evaluate if the Transformer can generalize to other tasks we performed experiments on English constituency parsing. This task presents speciﬁc challenges: the output is subject to strong structural constraints and is signiﬁcantly longer than the input. Furthermore, RNN sequence-to-sequence models have not been able to attain state-of-the-art results in small-data regimes [37].\n",
      "parent: '6.3 English Constituency Parsing' content: We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the Penn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting, using the larger high-conﬁdence and BerkleyParser corpora from with approximately 17M sentences [37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens for the semi-supervised setting.\n",
      "parent: '6.3 English Constituency Parsing' content: We performed only a small number of experiments to select the dropout, both attention and residual (section 5.4), learning rates and beam size on the Section 22 development set, all other parameters remained unchanged from the English-to-German base translation model. During inference, we\n",
      "9\n",
      "Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23 of WSJ)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead><th>Parser</th><th>Training</th><th>WSJ 23 F1</th></thead><tr><td>Vinyals &amp; Kaiser el al. (2014) B2</td><td>T WST only, discriminative</td><td>88.3</td></tr><tr><td>Petrov et al. (2006)</td><td>WSIJ only, discriminative</td><td>90.4</td></tr><tr><td>Zhu et al. (2013) [A0]</td><td>WSIJ only, discriminative</td><td>90.4</td></tr><tr><td>Dyer et al. (2016) (5]</td><td>WSJ only, discriminative</td><td>91.7</td></tr><tr><td>Transformer (4 layers)</td><td>WSIJ only, discriminative</td><td>91.3</td></tr><tr><td>Zhu et al. (2013) [A0]</td><td>semi-supervised</td><td>91.3</td></tr><tr><td>Vinyals Transformer (4 layers)</td><td>semi-supervised semi-supervised</td><td>92.7</td></tr><tr><td>Luong et al. (2015) 23]</td><td>multi-task</td><td>93.0</td></tr><tr><td>Dyer et al. (2016)</td><td>generative</td><td>93.3</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased the maximum output length to input length + 300. We used a beam size of 21 and ↵ = 0.3 for both WSJ only and the semi-supervised setting.\n",
      "Our results in Table 4 show that despite the lack of task-speciﬁc tuning our model performs sur- prisingly well, yielding better results than all previously reported models with the exception of the Recurrent Neural Network Grammar [8].\n",
      "In contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley- Parser [29] even when training only on the WSJ training set of 40K sentences.\n",
      "7 Conclusion\n",
      "parent: '7 Conclusion' content: In this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.\n",
      "parent: '7 Conclusion' content: For translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles.\n",
      "parent: '7 Conclusion' content: We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours.\n",
      "parent: '7 Conclusion' content: The code we used to train and evaluate our models is available at https://github.com/ tensorflow/tensor2tensor.\n",
      "parent: '7 Conclusion' content: Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
      "parent: '7 Conclusion' content: References [1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\n",
      "parent: '7 Conclusion' content: arXiv:1607.06450, 2016.\n",
      "parent: '7 Conclusion' content: [2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014.\n",
      "parent: '7 Conclusion' content: [3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.\n",
      "parent: '7 Conclusion' content: [4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine reading. arXiv preprint arXiv:1601.06733, 2016.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "parents = {}\n",
    "\n",
    "for el in elements:\n",
    "    parents[el.id] = el.text\n",
    "\n",
    "for el in elements:\n",
    "    if el.category == \"Table\":\n",
    "        display(HTML(el.metadata.text_as_html))\n",
    "    elif el.metadata.parent_id:\n",
    "        print(f\"parent: '{parents[el.metadata.parent_id]}' content: {el.text}\")\n",
    "    else:\n",
    "        print(el)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clearly see that Unstructured is parsing both table and document structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing into Astra DB\n",
    "\n",
    "Now we will continue with the RAG process, by creating embeddings for the pdf, and storing them in Astra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import AstraDB\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "astra_db_store = AstraDB(\n",
    "    collection_name=\"langchain_unstructured\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    token=os.getenv(\"ASTRA_DB_TOKEN\"),\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create LangChain Documents by splitting the text after `Table` elements and before `Title` elements. Additionally, we use the html output format for table data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cc7802558e4b431db3e683a9b6d0b892',\n",
       " '5778068445504853b9eba0c7c8b623eb',\n",
       " '4bf0439b4e484cc0851473f2838a5a9f',\n",
       " 'fc479ac7fada4edeb672f309f451df47']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = []\n",
    "current_doc = None\n",
    "\n",
    "for el in elements:\n",
    "    if el.category in [\"Header\", \"Footer\"]:\n",
    "        continue # skip these\n",
    "    if el.category == \"Title\":\n",
    "        documents.append(current_doc)\n",
    "        current_doc = None\n",
    "    if not current_doc:\n",
    "        current_doc = Document(page_content=\"\", metadata=el.metadata.to_dict())\n",
    "    current_doc.page_content += el.metadata.text_as_html if el.category == \"Table\" else el.text\n",
    "    if el.category == \"Table\":\n",
    "        documents.append(current_doc)\n",
    "        current_doc = None\n",
    "\n",
    "astra_db_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying\n",
    "\n",
    "Now that we have populated our vector store, we will build a RAG pipeline and execute some queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = \"\"\"\n",
    "Answer the question based only on the supplied context. If you don't know the answer, say \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Your answer:\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", streaming=False, temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": astra_db_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can ask a question about some text in the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reducing the attention key size hurts model quality.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What does reducing the attention key size do?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can try to get a value from the 2nd table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 'WSJ 23 F1' value for 'Dyer et al. (2016) (5]' was 91.7.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"For the transformer to English constituency results, what was the 'WSJ 23 F1' value for 'Dyer et al. (2016) (5]'?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can ask a question that doesn't exist in our content to confirm that the LLM rejection is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know. The context does not provide any information about George Washington's birthdate.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query fails to be answered due to lack of context in Astra DB\n",
    "chain.invoke(\"When was George Washington born?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
