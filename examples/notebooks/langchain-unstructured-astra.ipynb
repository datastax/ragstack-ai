{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Unstructured with LangChain & AstraDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show a basic RAG-style example that uses the Unstructured API to parse a PDF document, store the corresponding document into a vector store (`AstraDB`) and finally, perform some basic queries against that store. The notebook is modeled after the quick start notebooks and hence is meant as a way of getting started with Unstructured, backed by a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:48:33.967092Z",
     "start_time": "2024-02-13T11:47:41.568768Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, install the required dependencies\n",
    "!pip install --quiet ragstack-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:59:43.987486Z",
     "start_time": "2024-02-13T11:56:57.909870Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"UNSTRUCTURED_API_KEY\"] = getpass(\"Enter your Unstructured API Key:\")\n",
    "os.environ[\"ASTRA_DB_ENDPOINT\"] = input(\"Enter you Astra DB API Endpoint: \")\n",
    "os.environ[\"ASTRA_DB_TOKEN\"] = getpass(\"Enter you Astra DB Token: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Unstructured API to parse a PDF\n",
    "\n",
    "Note that we will use a simple, single-page PDF that was generated by the RAGstack team. We are using this because the free version of the Unstructured API is limited to 1,000 pages per month, and we don't want to use up too much of your credit with this example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:00:00.078294Z",
     "start_time": "2024-02-13T11:59:58.410498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download a simple PDF\n",
    "import requests\n",
    "\n",
    "# The URL of the file you want to download\n",
    "url = \"https://raw.githubusercontent.com/datastax/ragstack-ai/e0d91b269113bb4c26c8d68b1255a1f6b060f9a9/ragstack-e2e-tests/e2e_tests/resources/tree.pdf\"\n",
    "# The local path where you want to save the file\n",
    "file_path = \"./tree.pdf\"\n",
    "\n",
    "# Perform the HTTP request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open the file in binary write mode and save the content\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Error downloading the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:05:20.215552Z",
     "start_time": "2024-02-13T12:05:15.721697Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredAPIFileLoader\n",
    "\n",
    "loader = UnstructuredAPIFileLoader(\n",
    "    file_path=\"./tree.pdf\",\n",
    "    mode=\"single\",\n",
    "    strategy=\"auto\",\n",
    "    api_key=os.getenv(\"UNSTRUCTURED_API_KEY\"),\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:04:28.569279Z",
     "start_time": "2024-02-13T12:04:28.564364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute\n",
      "\n",
      "Value\n",
      "\n",
      "Type\n",
      "\n",
      "Broadleaf\n",
      "\n",
      "Height\n",
      "\n",
      "Can reach up to 100 ft\n",
      "\n",
      "Age\n",
      "\n",
      "Several centuries possible\n",
      "\n",
      "Leaf Color\n",
      "\n",
      "Green in Summer, Yellow/Brown in Autumn\n",
      "\n",
      "Once upon a time, in a lush meadow bordered by the whispering woods, stood a magnificent oak tree. This grand oak was known by all as Eldenroot, a sentinel that had watched over the land for countless generations. Eldenroot's branches stretched out like the arms of a wise elder, offering shade to travelers and a home to the creatures of the forest. Its leaves, a vibrant green throughout the warm months, turned into a fiery tapestry of reds, oranges, and yellows with the arrival of autumn. Legends spoke of its mystical beginnings, planted by nature spirits on a night when the moon shone brightest. Eldenroot was not just a tree; it was a timeless guardian, a keeper of secrets, and a symbol of the enduring beauty of nature.\n"
     ]
    }
   ],
   "source": [
    "# Take a quick look at the parsed text from the pdf:\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing into Astra DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import AstraDB\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "astra_db_store = AstraDB(\n",
    "    collection_name=\"langchain_unstructured\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    token=os.getenv(\"ASTRA_DB_TOKEN\"),\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['823a261e3c6242aaac1fd9066a9145a6']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "astra_db_store.add_documents(splitter.split_documents(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RAG Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt = \"\"\"\n",
    "Answer the question based only on the supplied context. If you don't know the answer, say \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Your answer:\n",
    "\"\"\"\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", streaming=False, temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": astra_db_store.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(prompt)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eldenroot was a magnificent oak tree.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What was Eldenroot?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at one of the source nodes from the response\n",
    "response_1.source_nodes[0].get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query fails to be answered due to lack of context in Astra DB\n",
    "chain.invoke(\"When was George Washington born?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
