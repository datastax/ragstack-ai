{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/RAG_with_cassio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pvPcHxhErXbg",
      "metadata": {
        "id": "pvPcHxhErXbg"
      },
      "source": [
        "# **RAGStack with CassIO**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oLHkt-bMq4up",
      "metadata": {
        "id": "oLHkt-bMq4up"
      },
      "source": [
        "## **Introduction**\n",
        "Large Language Models (LLMs) have a data freshness problem. The most powerful LLMs in the world, like GPT-4, have no idea about recent world events.\n",
        "\n",
        "The world of LLMs is frozen in time. Their world exists as a static snapshot of the world as it was within their training data.\n",
        "\n",
        "A solution to this problem is Retrieval Augmentated Generation (RAG). The idea behind this is that we retrieve relevant information from an external knowledge base and give that information to our LLM. In this notebook we will learn how to do that. In this demo, external or proprietary data will be stored in Astra DB and used to provide more current LLM responses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WQUeV_S5q4u0",
      "metadata": {
        "id": "WQUeV_S5q4u0"
      },
      "source": [
        "## **Prerequisites Setup**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Z1p8iUgjq4u2",
      "metadata": {
        "id": "Z1p8iUgjq4u2"
      },
      "source": [
        "* Follow [these steps](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html) to create a new vector search enabled database in Astra.\n",
        "* Generate a new [\"Database Administrator\" token](https://docs.datastax.com/en/astra-serverless/docs/manage/org/manage-tokens.html).\n",
        "* Download the secure connect bundle for the database you just created (you can do this from the \"Connect\" tab of your database).\n",
        "* You will also need the necessary secret for the LLM provider of your choice:\n",
        "  * If Open AI, then you will need an [Open AI API Key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key). This will require an Open AI account with billing enabled.\n",
        "  * If Vertex AI, you will need a config file.\n",
        "  * For more details, see [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2953d95b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2953d95b",
        "outputId": "f1d1a4dc-9984-405d-bf28-74697815ea12"
      },
      "outputs": [],
      "source": [
        "# install required dependencies\n",
        "! pip install ragstack-ai datasets google-cloud-aiplatform pandas "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222f44ff",
      "metadata": {
        "id": "222f44ff"
      },
      "source": [
        "You may be asked to \"Restart the Runtime\" at this time, as some dependencies\n",
        "have been upgraded. **Please do restart the runtime now** for a smoother execution from this point onward."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qSZ3-OG5Kdh6",
      "metadata": {
        "id": "qSZ3-OG5Kdh6"
      },
      "source": [
        "## **Astra DB Setup**\n",
        "The following steps will ask for the keyspace of the vector search enabled Astra DB that you want to use for this example, as well as the Astra DB Token that you generated as part of the prerequisites. You will also require to upload the [Secure Connect Bundle](https://awesome-astra.github.io/docs/pages/astra/download-scb/#c-procedure).\n",
        "\n",
        "Lastly, we are going to create helper functions for a secure connection to Astra DB `getCQLSession` `getCQLKeyspace` and `getTableCount`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zh4P-XUDq4u9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh4P-XUDq4u9",
        "outputId": "6108b384-addf-4b7a-e340-858a9ff76dfb"
      },
      "outputs": [],
      "source": [
        "# Input your database keyspace name:\n",
        "ASTRA_DB_KEYSPACE = input('Your Astra DB Keyspace name: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lThGqYchq4u-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lThGqYchq4u-",
        "outputId": "e5d8614f-54b3-47c0-df0d-b66ff1185354"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "# Input your Astra DB token string, the one starting with \"AstraCS:...\"\n",
        "ASTRA_DB_TOKEN_BASED_PASSWORD = getpass('Your Astra DB Token: ')\n",
        "# To avoid incompatibilities with existing tables, use a new table name\n",
        "ASTRA_DB_TABLE_NAME = input(\"Please provide the name of the table to be created: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xnNziXZ1q4vD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "xnNziXZ1q4vD",
        "outputId": "4802a65d-ff16-4f91-e99a-1776d710ec47"
      },
      "outputs": [],
      "source": [
        "# Upload your Secure Connect Bundle zipfile:\n",
        "# (Note - this notebook only works in google colab)\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "print('Please upload your Secure Connect Bundle')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    astraBundleFileTitle = list(uploaded.keys())[0]\n",
        "    ASTRA_DB_SECURE_BUNDLE_PATH = os.path.join(os.getcwd(), astraBundleFileTitle)\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Secure Connect Bundle. Please re-run the cell.'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TUDw-07Iq4vE",
      "metadata": {
        "id": "TUDw-07Iq4vE"
      },
      "outputs": [],
      "source": [
        "# colab-specific override of helper functions\n",
        "from cassandra.cluster import (\n",
        "    Cluster,\n",
        ")\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.query import SimpleStatement\n",
        "\n",
        "# The \"username\" is the literal string 'token' for this connection mode:\n",
        "ASTRA_DB_TOKEN_BASED_USERNAME = 'token'\n",
        "\n",
        "\n",
        "def getCQLSession(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        cluster = Cluster(\n",
        "            cloud={\n",
        "                \"secure_connect_bundle\": ASTRA_DB_SECURE_BUNDLE_PATH,\n",
        "            },\n",
        "            auth_provider=PlainTextAuthProvider(\n",
        "                ASTRA_DB_TOKEN_BASED_USERNAME,\n",
        "                ASTRA_DB_TOKEN_BASED_PASSWORD,\n",
        "            ),\n",
        "        )\n",
        "        astraSession = cluster.connect()\n",
        "        return astraSession\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getCQLKeyspace(mode='astra_db'):\n",
        "    if mode == 'astra_db':\n",
        "        return ASTRA_DB_KEYSPACE\n",
        "    else:\n",
        "        raise ValueError('Unsupported CQL Session mode')\n",
        "\n",
        "def getTableCount():\n",
        "  # create a query that counts the number of records of the Astra DB table\n",
        "  query = SimpleStatement(f\"\"\"SELECT COUNT(*) FROM {keyspace}.{table_name};\"\"\")\n",
        "\n",
        "  # execute the query\n",
        "  results = session.execute(query)\n",
        "  return results.one().count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QXCQ6T_Gjk0Oz",
      "metadata": {
        "id": "QXCQ6T_Gjk0Oz"
      },
      "source": [
        "## **LLM Provider**\n",
        "\n",
        "In the cell below you can choose between **GCP VertexAI** or **OpenAI** for your LLM services.\n",
        "(See [Pre-requisites](https://cassio.org/start_here/#llm-access) on cassio.org for more details).\n",
        "\n",
        "Make sure you set the `llmProvider` variable and supply the corresponding access secrets in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pGpzZc5zq4vG",
      "metadata": {
        "id": "pGpzZc5zq4vG"
      },
      "outputs": [],
      "source": [
        "# Set your secret(s) for LLM access:\n",
        "llmProvider = 'OpenAI'  # 'GCP_VertexAI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zOFStlEAq4vH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOFStlEAq4vH",
        "outputId": "3d28b021-0771-4f64-bce9-f9d598996ba5"
      },
      "outputs": [],
      "source": [
        "if llmProvider == 'OpenAI':\n",
        "    apiSecret = getpass(f'Your secret for LLM provider \"{llmProvider}\": ')\n",
        "    os.environ['OPENAI_API_KEY'] = apiSecret\n",
        "elif llmProvider == 'GCP_VertexAI':\n",
        "    # we need a json file\n",
        "    print(f'Please upload your Service Account JSON for the LLM provider \"{llmProvider}\":')\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        vertexAIJsonFileTitle = list(uploaded.keys())[0]\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.join(os.getcwd(), vertexAIJsonFileTitle)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            'No file uploaded. Please re-run the cell.'\n",
        "        )\n",
        "else:\n",
        "    raise ValueError('Unknown/unsupported LLM Provider')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eZS2Xsy0WY-c",
      "metadata": {
        "id": "eZS2Xsy0WY-c"
      },
      "source": [
        "# Provide Sample Data\n",
        "A sample document is provided from CassIO. You may provide your own files instead in the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OzxSvKT2W57Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzxSvKT2W57Z",
        "outputId": "3fee419d-7a20-463e-a5f2-ab926a75632d"
      },
      "outputs": [],
      "source": [
        "# retrieve the text of a short story that will be indexed in the vector store\n",
        "! curl https://raw.githubusercontent.com/CassioML/cassio-website/main/docs/frameworks/langchain/texts/amontillado.txt --output amontillado.txt\n",
        "SAMPLEDATA = [\"amontillado.txt\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternatively, provide your own file. However, you will want to update your queries to match the content of your file. \n",
        "\n",
        "# Upload sample file (Note: this assumes you are on Google Colab. Local Jupyter notebooks can provide the path to their files directly by uncommenting and running just the next line).\n",
        "# SAMPLEDATA = [\"<path_to_file>\"]\n",
        "\n",
        "print('Please upload your own sample file:')\n",
        "uploaded = files.upload()\n",
        "if uploaded:\n",
        "    SAMPLEDATA = uploaded\n",
        "else:\n",
        "    raise ValueError(\n",
        "        'Cannot proceed without Sample Data. Please re-run the cell.'\n",
        "    )\n",
        "\n",
        "\n",
        "print(f'Please make sure to change your queries to match the contents of your file!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6715bc2b",
      "metadata": {
        "id": "6715bc2b"
      },
      "source": [
        "# Vector Similarity Search QA Quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761d9b70",
      "metadata": {
        "id": "761d9b70"
      },
      "source": [
        "_**NOTE:** this uses Cassandra's \"Vector Similarity Search\" capability.\n",
        "Make sure you are connecting to a vector-enabled database for this demo._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4578a87b",
      "metadata": {
        "id": "4578a87b"
      },
      "source": [
        "A database connection is needed to access Cassandra. The following assumes\n",
        "that a _vector-search-capable Astra DB instance_ is available. Adjust as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11013224",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11013224",
        "outputId": "4bf5e8a3-036e-433e-9c2b-4f7e2b5fc157"
      },
      "outputs": [],
      "source": [
        "# Don't mind the \"Closing connection\" error after \"downgrading protocol...\" messages,\n",
        "# it is really just a warning: the connection will work smoothly.\n",
        "cqlMode = 'astra_db'\n",
        "session = getCQLSession(mode=cqlMode)\n",
        "keyspace = getCQLKeyspace(mode=cqlMode)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e2a156",
      "metadata": {
        "id": "32e2a156"
      },
      "source": [
        "Both an LLM and an embedding function are required.\n",
        "\n",
        "Below is the logic to instantiate the LLM and embeddings of choice. We choose to leave it in the notebooks for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "124e3de4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "124e3de4",
        "outputId": "1832f236-fe61-4773-e045-89358e647d04"
      },
      "outputs": [],
      "source": [
        "# creation of the LLM resources\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "if llmProvider == 'GCP_VertexAI':\n",
        "    from langchain.llms import VertexAI\n",
        "    from langchain.embeddings import VertexAIEmbeddings\n",
        "    llm = VertexAI()\n",
        "    myEmbedding = VertexAIEmbeddings()\n",
        "    print('LLM+embeddings from VertexAI')\n",
        "elif llmProvider == 'OpenAI':\n",
        "    from langchain.llms import OpenAI\n",
        "    from langchain.embeddings import OpenAIEmbeddings\n",
        "    llm = ChatOpenAI(temperature=0)\n",
        "    myEmbedding = OpenAIEmbeddings()\n",
        "    print('LLM+embeddings from OpenAI')\n",
        "else:\n",
        "    raise ValueError('Unknown LLM provider.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "285f29cf",
      "metadata": {
        "id": "285f29cf"
      },
      "source": [
        "## Langchain Retrieval Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cf74a31",
      "metadata": {
        "id": "5cf74a31"
      },
      "source": [
        "The following is a minimal usage of the Cassandra vector store. The store is created and filled at once, and is then queried to retrieve relevant parts of the indexed text, which are then stuffed into a prompt finally used to answer a question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SCxWxjRWl8Dg",
      "metadata": {
        "id": "SCxWxjRWl8Dg"
      },
      "outputs": [],
      "source": [
        "# Import the needed libraries and declare the LLM model\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Loop through each file and load it into our vector store\n",
        "documents = []\n",
        "for filename in SAMPLEDATA:\n",
        "  path = os.path.join(os.getcwd(), filename)\n",
        "\n",
        "  # Supported file types are pdf and txt\n",
        "  if filename.endswith(\".pdf\"):\n",
        "    loader = PyPDFLoader(path)\n",
        "    new_docs = loader.load_and_split()\n",
        "    print(f\"Processed pdf file: {filename}\")\n",
        "  elif filename.endswith(\".txt\"):\n",
        "    loader = TextLoader(path)\n",
        "    new_docs = loader.load_and_split()\n",
        "    print(f\"Processed txt file: {filename}\")\n",
        "  else:\n",
        "    print(f\"Unsupported file type: {filename}\")\n",
        "\n",
        "  if len(new_docs) > 0:\n",
        "    documents.extend(new_docs)\n",
        "\n",
        "cassVStore = Cassandra.from_documents(\n",
        "  documents=documents,\n",
        "  embedding=OpenAIEmbeddings(),\n",
        "  session=session,\n",
        "  keyspace=ASTRA_DB_KEYSPACE,\n",
        "  table_name=ASTRA_DB_TABLE_NAME,\n",
        ")\n",
        "\n",
        "# empty the list of file names -- we don't want to accidentally load the same files again\n",
        "SAMPLEDATA = []\n",
        "\n",
        "print(f\"\\nProcessing done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pQUQd1uSNe2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQUQd1uSNe2G",
        "outputId": "ac074f20-2dbd-4e02-8ec7-b9c4afbe0865"
      },
      "outputs": [],
      "source": [
        "from cassandra.query import SimpleStatement\n",
        "\n",
        "# create a query that returns the 3 rows of the Astra DB table\n",
        "cqlSelect = SimpleStatement(f\"\"\"SELECT * from {keyspace}.{ASTRA_DB_TABLE_NAME} limit 3;\"\"\")\n",
        "\n",
        "rows = session.execute(cqlSelect)\n",
        "for row_i, row in enumerate(rows):\n",
        "    print(f'\\nRow {row_i}:')\n",
        "    print(f'    row_id:      {row.row_id}')\n",
        "    print(f'    vector: {str(row.vector)[:64]} ...')\n",
        "    print(f'    body_blob:         {row.body_blob} ...')\n",
        "\n",
        "print('\\n...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "geA-eXncFwvi",
      "metadata": {
        "id": "geA-eXncFwvi"
      },
      "source": [
        "Now let's query our proprietary store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cEp-I8wd5Abv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "cEp-I8wd5Abv",
        "outputId": "1f818fff-2fe9-4a29-cbfa-0e41193f3fbe"
      },
      "outputs": [],
      "source": [
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "\n",
        "index = VectorStoreIndexWrapper(vectorstore=cassVStore)\n",
        "query = \"Who is Luchesi?\"\n",
        "index.query(query,llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S_96yaY45OFw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S_96yaY45OFw",
        "outputId": "16f149e4-766f-44b6-f8ea-326153c1fc24"
      },
      "outputs": [],
      "source": [
        "query = \"What motivates Montresor to seek revenge against Fortunato?\"\n",
        "index.query(query,llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dg1FUbYoudSr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg1FUbYoudSr",
        "outputId": "10478b4d-d1d2-4d58-a450-38d045deb239"
      },
      "outputs": [],
      "source": [
        "# We can query the index for the relevant documents, which act as context for the LLM. \n",
        "retriever = index.vectorstore.as_retriever(search_kwargs={\n",
        "    'k': 2, # retrieve 2 documents\n",
        "})\n",
        "retriever.get_relevant_documents(\n",
        "    \"What motivates Montresor to seek revenge against Fortunado?\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
