{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using llama-parse with AstraDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show a basic RAG-style example that uses `llama-parse` to parse a PDF document, store the corresponding document into a vector store (`AstraDB`) and finally, perform some basic queries against that store. The notebook is modeled after the quick start notebooks and hence is meant as a way of getting started with `llama-parse`, backed by a vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:48:33.967092Z",
     "start_time": "2024-02-13T11:47:41.568768Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, install the required dependencies\n",
    "!pip install --quiet llama-index llama-parse llama-index-vector-stores-astra llama-index-llms-openai astrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:59:43.987486Z",
     "start_time": "2024-02-13T11:56:57.909870Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = getpass(\"Enter your Llama Index Cloud API Key:\")\n",
    "os.environ[\"ASTRA_DB_ENDPOINT\"] = input(\"Enter you Astra DB API Endpoint: \")\n",
    "os.environ[\"ASTRA_DB_TOKEN\"] = getpass(\"Enter you Astra DB Token: \")\n",
    "os.environ[\"OPEN_AI_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T11:59:49.055038Z",
     "start_time": "2024-02-13T11:59:49.048554Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the sync code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using llama-parse to parse a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:00:00.078294Z",
     "start_time": "2024-02-13T11:59:58.410498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab a PDF from Arxiv for indexing\n",
    "import requests \n",
    "\n",
    "# The URL of the file you want to download\n",
    "url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
    "# The local path where you want to save the file\n",
    "file_path = \"./attention.pdf\"\n",
    "\n",
    "# Perform the HTTP request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Open the file in binary write mode and save the content\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"Error downloading the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:05:20.215552Z",
     "start_time": "2024-02-13T12:05:15.721697Z"
    }
   },
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "documents = LlamaParse(result_type=\"text\", verbose=True).load_data(\"./attention.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T12:04:28.569279Z",
     "start_time": "2024-02-13T12:04:28.564364Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a quick look at some of the parsed text from the document:\n",
    "documents[0].get_content()[10000:11000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing into Astra DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.vector_stores.astra import AstraDBVectorStore\n",
    "\n",
    "astra_db_store = AstraDBVectorStore(\n",
    "    token=os.environ[\"ASTRA_DB_TOKEN\"],\n",
    "    api_endpoint=os.environ[\"ASTRA_DB_ENDPOINT\"],\n",
    "    collection_name=\"astra_v_table_llamaparse\",\n",
    "    embedding_dimension=1536\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "node_parser = SimpleNodeParser()\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=astra_db_store)\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=OpenAIEmbedding(api_key=os.environ[\"OPEN_AI_KEY\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RAG Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Multi-Head Attention also known as?\"\n",
    "\n",
    "response_1 = query_engine.query(query)\n",
    "print(\"\\n***********New LlamaParse+ Basic Query Engine***********\")\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at one of the source nodes from the response\n",
    "response_1.source_nodes[0].get_content()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
