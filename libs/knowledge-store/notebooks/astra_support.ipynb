{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/326.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.9/18.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for bson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ragstack-ai-langchain[knowledge-store] beautifulsoup4 markdownify python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Astra Documentation into Graph Store\n",
    "\n",
    "First, we'll crawl the DataStax documentation. LangChain includes a `SiteMapLoader` but it loads all of the pages into memory simultaneously, which makes it impossible to index larger sites from small environments (such as CoLab). So, we'll scrape the sitemap ourselves and iterate over the URLs, allowing us to process documents in batches and flush them to Astra DB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the URLs from the Site Maps\n",
    "First, we use Beautiful Soup to parse the XML content of each sitemap and get the list of URLs.\n",
    "We also add a few extra URLs for external sites that are also useful to include in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use sitemaps to crawl the content\n",
    "SITEMAPS = [\n",
    "    \"https://docs.datastax.com/en/sitemap-astra-db-vector.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-cql.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-dev-app-drivers.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-glossary.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-astra-db-serverless.xml\",\n",
    "]\n",
    "\n",
    "# Additional URLs to crawl for content.\n",
    "EXTRA_URLS = [\"https://github.com/jbellis/jvector\"]\n",
    "\n",
    "SITE_PREFIX = \"astra\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def load_pages(sitemap_url):\n",
    "    r = requests.get(\n",
    "        sitemap_url,\n",
    "        headers={\n",
    "            # Astra docs only return a sitemap with a user agent set.\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:58.0) Gecko/20100101 Firefox/58.0\",\n",
    "        },\n",
    "    )\n",
    "    xml = r.text\n",
    "\n",
    "    soup = BeautifulSoup(xml, features=\"xml\")\n",
    "    url_tags = soup.find_all(\"url\")\n",
    "    for url in url_tags:\n",
    "        yield (url.find(\"loc\").text)\n",
    "\n",
    "\n",
    "# For maintenance purposes, we could check only the new articles since a given time.\n",
    "URLS = [url for sitemap_url in SITEMAPS for url in load_pages(sitemap_url)] + EXTRA_URLS\n",
    "len(URLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the content from each URL\n",
    "Next, we create the code to load each page. This performs the following steps:\n",
    "\n",
    "1. Parses the HTML with BeautifulSoup\n",
    "2. Locates the \"content\" of the HTML using an appropriate selector based on the URL\n",
    "3. Find the link (`<a href=\"...\">`) tags in the content and collect the absolute URLs (for creating edges).\n",
    "\n",
    "Adding the URLs of these references to the metadata allows the graph store to create edges between the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/benjamin.chambers/code/ragstack-ai/libs/knowledge-store/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "from typing import AsyncIterator, Iterable\n",
    "from ragstack_knowledge_store.graph_store import CONTENT_ID\n",
    "from markdownify import MarkdownConverter\n",
    "from ragstack_langchain.graph_store.extractors import HtmlLinkEdgeExtractor\n",
    "\n",
    "markdown_converter = MarkdownConverter(heading_style=\"ATX\")\n",
    "html_link_extractor = HtmlLinkEdgeExtractor()\n",
    "\n",
    "\n",
    "def select_content(soup: BeautifulSoup, url: str) -> BeautifulSoup:\n",
    "    if url.startswith(\"https://docs.datastax.com/en/\"):\n",
    "        return soup.select_one(\"article.doc\")\n",
    "    elif url.startswith(\"https://github.com\"):\n",
    "        return soup.select_one(\"article.entry-content\")\n",
    "    else:\n",
    "        return soup\n",
    "\n",
    "\n",
    "async def load_pages(urls: Iterable[str]) -> AsyncIterator[Document]:\n",
    "    loader = AsyncHtmlLoader(\n",
    "        urls,\n",
    "        requests_per_second=4,\n",
    "        # Astra docs require a user agent\n",
    "        header_template={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:58.0) Gecko/20100101 Firefox/58.0\"\n",
    "        },\n",
    "    )\n",
    "    async for html in loader.alazy_load():\n",
    "        url = html.metadata[\"source\"]\n",
    "\n",
    "        # Use the URL as the content ID.\n",
    "        html.metadata[CONTENT_ID] = url\n",
    "\n",
    "        # Apply the selectors while loading. This reduces the size of\n",
    "        # the document as early as possible for reduced memory usage.\n",
    "        soup = BeautifulSoup(html.page_content, \"html.parser\")\n",
    "        content = select_content(soup, url)\n",
    "\n",
    "        # Extract HTML links from the content.\n",
    "        html_link_extractor.extract_one(html, content)\n",
    "\n",
    "        # Convert the content to markdown\n",
    "        html.page_content = markdown_converter.convert_soup(content)\n",
    "\n",
    "        yield html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n",
    "Before we initialize the Graph Store and write the documents we need to set some environment variables.\n",
    "In colab, this will prompt you for input. When running locally, this will load from `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in colab. Loading '.env' (see 'env.template' for example)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # (Option 1) - Set the environment variables from getpass.\n",
    "    print(\"In colab. Using getpass/input for environment variables.\")\n",
    "    import getpass\n",
    "    import os\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    os.environ[\"ASTRA_DB_DATABASE_ID\"] = input(\"Enter Astra DB Database ID: \")\n",
    "    os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = getpass.getpass(\n",
    "        \"Enter Astra DB Application Token: \"\n",
    "    )\n",
    "\n",
    "    keyspace = input(\"Enter Astra DB Keyspace (Empty for default): \")\n",
    "    if keyspace:\n",
    "        os.environ[\"ASTRA_DB_KEYSPACE\"] = keyspace\n",
    "    else:\n",
    "        os.environ.pop(\"ASTRA_DB_KEYSPACE\", None)\n",
    "else:\n",
    "    print(\"Not in colab. Loading '.env' (see 'env.template' for example)\")\n",
    "    import dotenv\n",
    "\n",
    "    dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Cassio and Graph Store\n",
    "With the environment variables set we initialize the Cassio library for talking to Cassandra / Astra DB.\n",
    "We also create the `GraphStore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_PREFIX = \"astra_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "ERROR:cassandra.connection:Closing connection <LibevConnection(4414837392) 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
      "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING:cassandra.cluster:Found multiple hosts with the same endpoint (4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703). Excluding peer 10.16.22.5\n"
     ]
    }
   ],
   "source": [
    "answer = input(\"Drop Tables? [(Y)es/(N)o]\")\n",
    "if answer.lower() in [\"y\", \"yes\"]:\n",
    "    import cassio\n",
    "\n",
    "    cassio.init(auto=True)\n",
    "    from cassio.config import check_resolve_session, check_resolve_keyspace\n",
    "\n",
    "    session = check_resolve_session()\n",
    "    keyspace = check_resolve_keyspace()\n",
    "    session.execute(f\"DROP TABLE IF EXISTS {keyspace}.{SITE_PREFIX}_nodes\")\n",
    "    session.execute(f\"DROP TABLE IF EXISTS {keyspace}.{SITE_PREFIX}_targets\")\n",
    "else:\n",
    "    # Handle no / \"wrong\" input\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
      "WARNING:cassandra.cluster:Found multiple hosts with the same endpoint (4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703). Excluding peer 10.16.22.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:cassandra.connection:Closing connection <LibevConnection(5131913040) 4f913ede-cf76-4f98-b390-907743bafd85-us-east1.db.astra.datastax.com:29042:405388e3-1a02-4604-87ca-d3c869677703> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
      "WARNING:cassandra.protocol:Server warning: Detected collection link_to_tags with 49 items, greater than the maximum recommended (20)\n",
      "WARNING:cassandra.protocol:Server warning: Detected collection link_to_tags with 25 items, greater than the maximum recommended (20)\n"
     ]
    }
   ],
   "source": [
    "import cassio\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from ragstack_langchain.graph_store import CassandraGraphStore\n",
    "\n",
    "cassio.init(auto=True)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "graph_store = CassandraGraphStore(\n",
    "    embeddings, node_table=f\"{SITE_PREFIX}_nodes\", edge_table=f\"{SITE_PREFIX}_edges\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Documents\n",
    "Finally, we fetch pages and write them to the graph store in batches of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages:  71%|#######1  | 976/1373 [02:39<00:51,  7.70it/s]WARNING:langchain_community.document_loaders.async_html:Error fetching https://docs.datastax.com/en/cql/astra/developing/inserting/update-counter.html with attempt 1/3: Cannot connect to host docs.datastax.com:443 ssl:default [nodename nor servname provided, or not known]. Retrying...\n",
      "Fetching pages: 100%|##########| 1373/1373 [03:46<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 (of 1373) URLs were not found\n"
     ]
    }
   ],
   "source": [
    "not_found = 0\n",
    "found = 0\n",
    "\n",
    "docs = []\n",
    "async for doc in load_pages(URLS):\n",
    "    if doc.page_content.startswith(\"\\n# Page Not Found\"):\n",
    "        not_found += 1\n",
    "        continue\n",
    "\n",
    "    docs.append(doc)\n",
    "    found += 1\n",
    "\n",
    "    if len(docs) >= 50:\n",
    "        graph_store.add_documents(docs)\n",
    "        docs.clear()\n",
    "\n",
    "if docs:\n",
    "    graph_store.add_documents(docs)\n",
    "print(f\"{not_found} (of {not_found + found}) URLs were not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and execute the RAG Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "template = \"\"\"You are a helpful technical support bot. You should provide complete answers explaining the options the user has available to address their problem. Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted = \"\\n\\n\".join(\n",
    "        f\"From {doc.metadata['content_id']}: {doc.page_content}\" for doc in docs\n",
    "    )\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the following question. This is an interesting question because the ideal answer should be concise and in-depth, based on how the vector indexing is actually implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What vector indexing algorithms does Astra use?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# Helper method to render markdown in responses to a chain.\n",
    "def run_and_render(chain, question):\n",
    "    result = chain.invoke(question)\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-Only Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 0 doesn't traverses edges and is equivalent to vector similarity only.\n",
    "vector_retriever = graph_store.as_retriever(search_kwargs={\"depth\": 0})\n",
    "\n",
    "vector_rag_chain = (\n",
    "    {\"context\": vector_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Astra DB Serverless uses multiple indexing techniques to speed up vector searches. The primary vector indexing algorithms and techniques include:\n",
       "\n",
       "1. **JVector**:\n",
       "   - **Description**: The Serverless (Vector) database uses the JVector vector search engine to construct a graph index.\n",
       "   - **Features**: JVector adds new documents to the graph immediately, allowing for efficient searches right away. It can also compress vectors with quantization to save space and improve performance.\n",
       "   - **Further Information**: [JVector on GitHub](https://github.com/jbellis/jvector)\n",
       "\n",
       "2. **Storage-Attached Index (SAI)**:\n",
       "   - **Description**: SAI is an indexing technique used to efficiently find rows that satisfy query predicates. Astra DB provides numeric-, text-, and vector-based indexes to support different kinds of searches.\n",
       "   - **Features**: SAI can be customized based on specific requirements, such as a particular similarity function or text transformation. When a search is run, SAI loads a superset of possible results from storage based on the provided predicates and sorts the results by vector similarity. The top `limit` results are then returned to the user.\n",
       "   - **Further Information**: [Storage-Attached Indexing (SAI) Overview](https://docs.datastax.com/en/cql/astra/developing/indexing/sai/sai-overview.html)\n",
       "\n",
       "These indexing techniques are designed to make vector searches faster and more efficient, supporting a variety of use cases such as semantic search, AI applications, and more."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_and_render(vector_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Traversal Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 1 does vector similarity and then traverses 1 level of edges.\n",
    "graph_retriever = graph_store.as_retriever(search_kwargs={\"depth\": 1})\n",
    "\n",
    "graph_rag_chain = (\n",
    "    {\"context\": graph_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Astra DB Serverless utilizes the JVector vector search engine to construct a graph index for vector databases. The JVector engine is part of the DiskANN family of graph-based index algorithms, which are known for their efficiency and scalability in high-dimensional spaces. \n",
       "\n",
       "### Key Features of JVector:\n",
       "1. **Graph-Based Index**: JVector constructs a single-layer graph with nonblocking concurrency control, allowing the index to scale linearly with the number of cores.\n",
       "2. **Two-Pass Search**: The search process in JVector includes a first pass powered by lossily compressed representations of the vectors kept in memory and a second pass using a more accurate representation read from disk.\n",
       "3. **Compression Techniques**:\n",
       "   - **Product Quantization (PQ)**: Used to compress vectors for efficient storage and search.\n",
       "   - **Binary Quantization (BQ)**: Another method of compression, though generally less useful than PQ due to its impact on search accuracy.\n",
       "   - **Fused ADC**: An advanced method where PQ codebooks are transposed and written inline with the graph adjacency list, improving the efficiency of the search.\n",
       "\n",
       "### Why Graph-Based Indexing?\n",
       "Graph-based indexes, such as JVector, are preferred for several reasons:\n",
       "- **Incremental Construction and Updates**: Unlike partition-based indexes, graph-based indexes can be constructed and updated incrementally, making them suitable for dynamic datasets.\n",
       "- **Performance**: Graph-based indexes tend to be faster and simpler to implement.\n",
       "- **Scalability**: They support large-scale datasets and can handle high-dimensional vector spaces efficiently.\n",
       "\n",
       "### Comparison to Other ANN Indexes:\n",
       "- **Partition-Based Indexes**: Examples include LSH (Locality-Sensitive Hashing) and IVF (Inverted File Index). These are typically better suited for static datasets and might not perform as well as graph-based indexes in dynamic environments.\n",
       "- **Graph-Based Indexes**: Examples include HNSW (Hierarchical Navigable Small World) and DiskANN. These indexes are favored for their incremental update capabilities and overall efficiency in high-dimensional spaces.\n",
       "\n",
       "### Conclusion:\n",
       "Astra DB Serverless leverages JVector, a sophisticated graph-based index, to provide efficient and scalable vector search capabilities. This choice aligns with the needs of modern applications that require real-time updates and high performance in handling large, high-dimensional datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_and_render(graph_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMR Graph Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_graph_retriever = graph_store.as_retriever(\n",
    "    search_type=\"mmr_traversal\",\n",
    "    search_kwargs={\n",
    "        \"k\": 4,\n",
    "        \"fetch_k\": 10,\n",
    "        \"depth\": 2,\n",
    "        # \"score_threshold\": 0.2,\n",
    "    },\n",
    ")\n",
    "\n",
    "mmr_graph_rag_chain = (\n",
    "    {\"context\": mmr_graph_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Astra DB Serverless uses multiple vector indexing techniques to speed up searches. Specifically, it uses:\n",
       "\n",
       "1. **JVector**: Astra DB utilizes the JVector vector search engine to construct a graph index. JVector is a graph-based index that builds on the DiskANN design. It constructs a single-layer graph with nonblocking concurrency control, which allows for scalable construction with the number of cores. JVector can also compress vectors using techniques like product quantization to save space and improve performance.\n",
       "\n",
       "2. **Storage-Attached Index (SAI)**: SAI is another indexing technique available in Astra DB to efficiently find rows that satisfy query predicates. It supports numeric-, text-, and vector-based indexes which can be customized based on specific requirements. When running a search, SAI loads a superset of all possible results from storage based on the predicates provided and evaluates the search criteria, sorting the results by vector similarity before returning the top results.\n",
       "\n",
       "These indexing methods are designed to optimize the performance and efficiency of vector searches within Astra DB Serverless."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_and_render(mmr_graph_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Retrieval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector [0]:    https://docs.datastax.com/en/astra-db-serverless/get-started/concepts.html\n",
      "Vector [1]:    https://docs.datastax.com/en/cql/astra/getting-started/vector-search-quickstart.html\n",
      "Vector [2]:    https://docs.datastax.com/en/cql/astra/developing/indexing/indexing-concepts.html\n",
      "Vector [3]:    https://docs.datastax.com/en/astra-db-serverless/databases/database-overview.html\n",
      "Vector took 0.4749s\n",
      "Graph [0]:     https://docs.datastax.com/en/astra-db-serverless/get-started/concepts.html\n",
      "Graph [1]:     https://docs.datastax.com/en/cql/astra/getting-started/vector-search-quickstart.html\n",
      "Graph [2]:     https://docs.datastax.com/en/cql/astra/developing/indexing/indexing-concepts.html\n",
      "Graph [3]:     https://docs.datastax.com/en/astra-db-serverless/databases/database-overview.html\n",
      "Graph [4]:     https://docs.datastax.com/en/glossary/index.html\n",
      "Graph [5]:     https://docs.datastax.com/en/astra-db-serverless/administration/maintenance-schedule.html\n",
      "Graph [6]:     https://docs.datastax.com/en/cql/astra/developing/indexing/sai/sai-overview.html\n",
      "Graph [7]:     https://docs.datastax.com/en/astra-db-serverless/tutorials/recommendations.html\n",
      "Graph [8]:     https://docs.datastax.com/en/astra-db-serverless/administration/support.html\n",
      "Graph [9]:     https://docs.datastax.com/en/astra-db-serverless/tutorials/chatbot.html\n",
      "Graph [10]:     https://docs.datastax.com/en/astra-db-serverless/integrations/semantic-kernel.html\n",
      "Graph [11]:     https://github.com/jbellis/jvector\n",
      "Graph [12]:     https://docs.datastax.com/en/astra-db-serverless/databases/database-limits.html\n",
      "Graph [13]:     https://docs.datastax.com/en/astra-db-serverless/databases/backup-restore.html\n",
      "Graph took 0.9744s\n",
      "MMR Graph [0]: https://docs.datastax.com/en/astra-db-serverless/get-started/concepts.html\n",
      "MMR Graph [1]: https://docs.datastax.com/en/astra-db-serverless/cli-reference/astra-cli.html\n",
      "MMR Graph [2]: https://github.com/jbellis/jvector\n",
      "MMR Graph [3]: https://docs.datastax.com/en/cql/astra/developing/indexing/indexing-concepts.html\n",
      "MMR Graph took 1.3907s\n"
     ]
    }
   ],
   "source": [
    "# Set the question and see what documents each technique retrieves.\n",
    "for i, doc in enumerate(vector_retriever.invoke(QUESTION)):\n",
    "    print(f\"Vector [{i}]:    {doc.metadata['content_id']}\")\n",
    "\n",
    "for i, doc in enumerate(graph_retriever.invoke(QUESTION)):\n",
    "    print(f\"Graph [{i}]:     {doc.metadata['content_id']}\")\n",
    "\n",
    "for i, doc in enumerate(mmr_graph_retriever.invoke(QUESTION)):\n",
    "    print(f\"MMR Graph [{i}]: {doc.metadata['content_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "With vector only we retrieved chunks from the Astra documentation explaining that it used JVector.\n",
    "Since it didn't follow the link to [JVector on GitHub](https://github.com/jbellis/jvector) it didn't actually answer the question.\n",
    "\n",
    "The graph retrieval started with the same set of chunks, but it followed the edge to the documents we loaded from GitHub.\n",
    "This allowed the LLM to read in more depth how JVector is implemented, which allowed it to answer the question more clearly and with more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-aiP65pJh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
