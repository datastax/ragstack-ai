{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain-community in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: langchain-openai in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: markdownify in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (0.12.1)\n",
      "Requirement already satisfied: python-dotenv in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: ragstack-ai-knowledge-store in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-core) (0.1.63)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-core) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-core) (8.3.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-community) (0.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-community) (2.32.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-openai) (1.30.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six<2,>=1.15 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from markdownify) (1.16.0)\n",
      "Requirement already satisfied: cassio<0.2.0,>=0.1.7 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from ragstack-ai-knowledge-store) (0.1.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: cassandra-driver<4.0.0,>=3.28.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store) (3.29.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (4.12.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store) (0.2.1.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: click in /Users/benjamin.chambers/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio<0.2.0,>=0.1.7->ragstack-ai-knowledge-store) (8.1.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core langchain-community langchain-openai beautifulsoup4 markdownify python-dotenv ragstack-ai-knowledge-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Astra Documentation into Graph Store\n",
    "\n",
    "First, we'll crawl the DataStax documentation. LangChain includes a `SiteMapLoader` but it loads all of the pages into memory simultaneously, which makes it impossible to index larger sites from small environments (such as CoLab). So, we'll scrape the sitemap ourselves and iterate over the URLs, allowing us to process documents in batches and flush them to Astra DB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the URLs from the Site Maps\n",
    "First, we use Beautiful Soup to parse the XML content of each sitemap and get the list of URLs.\n",
    "We also add a few extra URLs for external sites that are also useful to include in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use sitemaps to crawl the content\n",
    "SITEMAPS = [\n",
    "    \"https://docs.datastax.com/en/sitemap-astra-db-vector.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-cql.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-dev-app-drivers.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-glossary.xml\",\n",
    "    \"https://docs.datastax.com/en/sitemap-astra-db-serverless.xml\"\n",
    "]\n",
    "\n",
    "# Additional URLs to crawl for content.\n",
    "EXTRA_URLS = [\n",
    "    \"https://github.com/jbellis/jvector\"\n",
    "]\n",
    "\n",
    "SITE_PREFIX = \"astra\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def load_pages(sitemap_url):\n",
    "    r = requests.get(sitemap_url,\n",
    "                     headers={\n",
    "                         # Astra docs only return a sitemap with a user agent set.\n",
    "                         \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:58.0) Gecko/20100101 Firefox/58.0\",\n",
    "                     })\n",
    "    xml = r.text\n",
    "\n",
    "    soup = BeautifulSoup(xml, features=\"xml\")\n",
    "    url_tags = soup.find_all(\"url\")\n",
    "    for url in url_tags:\n",
    "        yield(url.find(\"loc\").text)\n",
    "\n",
    "\n",
    "# For maintenance purposes, we could check only the new articles since a given time.\n",
    "URLS = [\n",
    "    url\n",
    "    for sitemap_url in SITEMAPS\n",
    "    for url in load_pages(sitemap_url)\n",
    "] + EXTRA_URLS\n",
    "len(URLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the content from each URL\n",
    "Next, we create the code to load each page. This performs the following steps:\n",
    "\n",
    "1. Parses the HTML with BeautifulSoup\n",
    "2. Locates the \"content\" of the HTML using an appropriate selector based on the URL\n",
    "3. Find the link (`<a href=\"...\">`) tags in the content and collect the absolute URLs (for creating edges).\n",
    "\n",
    "Adding the URLs of these references to the metadata allows the graph store to create edges between the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "from typing import AsyncIterator, Iterable\n",
    "from ragstack_knowledge_store.graph_store import CONTENT_ID\n",
    "from markdownify import MarkdownConverter\n",
    "from ragstack_knowledge_store.langchain.extractors import HtmlLinkEdgeExtractor\n",
    "\n",
    "markdown_converter = MarkdownConverter(heading_style=\"ATX\")\n",
    "html_link_extractor = HtmlLinkEdgeExtractor()\n",
    "\n",
    "def select_content(soup: BeautifulSoup, url: str) -> BeautifulSoup:\n",
    "    if url.startswith(\"https://docs.datastax.com/en/\"):\n",
    "        return soup.select_one(\"article.doc\")\n",
    "    elif url.startswith(\"https://github.com\"):\n",
    "        return soup.select_one(\"article.entry-content\")\n",
    "    else:\n",
    "        return soup\n",
    "\n",
    "async def load_pages(urls: Iterable[str]) -> AsyncIterator[Document]:\n",
    "    loader = AsyncHtmlLoader(\n",
    "        urls,\n",
    "        requests_per_second=4,\n",
    "        # Astra docs require a user agent\n",
    "        header_template = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:58.0) Gecko/20100101 Firefox/58.0\"\n",
    "        }\n",
    "    )\n",
    "    async for html in loader.alazy_load():\n",
    "        url = html.metadata[\"source\"]\n",
    "\n",
    "        # Use the URL as the content ID.\n",
    "        html.metadata[CONTENT_ID] = url\n",
    "\n",
    "        # Apply the selectors while loading. This reduces the size of\n",
    "        # the document as early as possible for reduced memory usage.\n",
    "        soup = BeautifulSoup(html.page_content, \"html.parser\")\n",
    "        content = select_content(soup, url)\n",
    "\n",
    "        # Extract HTML links from the content.\n",
    "        html_link_extractor.extract_one(html, content)\n",
    "\n",
    "        # Convert the content to markdown\n",
    "        html.page_content = markdown_converter.convert_soup(content)\n",
    "\n",
    "        yield html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n",
    "Before we initialize the Graph Store and write the documents we need to set some environment variables.\n",
    "In colab, this will prompt you for input. When running locally, this will load from `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in colab. Loading '.env' (see 'env.template' for example)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    # (Option 1) - Set the environment variables from getpass.\n",
    "    print(\"In colab. Using getpass/input for environment variables.\")\n",
    "    import getpass\n",
    "    import os\n",
    "\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    os.environ[\"ASTRA_DB_DATABASE_ID\"] = input(\"Enter Astra DB Database ID: \")\n",
    "    os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = getpass.getpass(\"Enter Astra DB Application Token: \")\n",
    "\n",
    "    keyspace = input(\"Enter Astra DB Keyspace (Empty for default): \")\n",
    "    if keyspace:\n",
    "        os.environ[\"ASTRA_DB_KEYSPACE\"] = keyspace\n",
    "    else:\n",
    "        os.environ.pop(\"ASTRA_DB_KEYSPACE\", None)\n",
    "else:\n",
    "    print(\"Not in colab. Loading '.env' (see 'env.template' for example)\")\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Cassio and Graph Store\n",
    "With the environment variables set we initialize the Cassio library for talking to Cassandra / Astra DB.\n",
    "We also create the `GraphStore`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_PREFIX=\"astra_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = input(\"Drop Tables? [(Y)es/(N)o]\")\n",
    "if answer.lower() in [\"y\",\"yes\"]:\n",
    "    import cassio\n",
    "    cassio.init(auto=True)\n",
    "    from cassio.config import check_resolve_session, check_resolve_keyspace\n",
    "    session = check_resolve_session()\n",
    "    keyspace = check_resolve_keyspace()\n",
    "    session.execute(f\"DROP TABLE IF EXISTS {keyspace}.{SITE_PREFIX}_nodes\")\n",
    "    session.execute(f\"DROP TABLE IF EXISTS {keyspace}.{SITE_PREFIX}_targets\")\n",
    "else:\n",
    "    # Handle no / \"wrong\" input\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cassio\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from ragstack_knowledge_store.langchain import CassandraKnowledgeStore\n",
    "\n",
    "cassio.init(auto=True)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "graph_store = CassandraGraphStore(\n",
    "    embeddings,\n",
    "    node_table=f\"{SITE_PREFIX}_nodes\",\n",
    "    targets_table=f\"{SITE_PREFIX}_targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Documents\n",
    "Finally, we fetch pages and write them to the graph store in batches of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1373/1373 [03:52<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 (of 1373) URLs were not found\n"
     ]
    }
   ],
   "source": [
    "not_found = 0\n",
    "found = 0\n",
    "\n",
    "docs = []\n",
    "async for doc in load_pages(URLS):\n",
    "    if doc.page_content.startswith(\"\\n# Page Not Found\"):\n",
    "        not_found += 1\n",
    "        continue\n",
    "\n",
    "    docs.append(doc)\n",
    "    found += 1\n",
    "\n",
    "    if len(docs) >= 50:\n",
    "        graph_store.add_documents(docs)\n",
    "        docs.clear()\n",
    "\n",
    "if docs:\n",
    "    graph_store.add_documents(docs)\n",
    "print(f\"{not_found} (of {not_found + found}) URLs were not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and execute the RAG Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "template = \"\"\"You are a helpful technical support bot. You should provide complete answers explaining the options the user has available to address their problem. Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted = \"\\n\\n\".join(f\"From {doc.metadata['content_id']}: {doc.page_content}\" for doc in docs)\n",
    "    return formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the following question. This is an interesting question because the ideal answer should be concise and in-depth, based on how the vector indexing is actually implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION=\"What vector indexing algorithms does Astra use?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Helper method to render markdown in responses to a chain.\n",
    "def run_and_render(chain, question):\n",
    "    result = chain.invoke(question)\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector-Only Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 0 doesn't traverses edges and is equivalent to vector similarity only.\n",
    "vector_retriever = graph_store.as_retriever(search_kwargs={\"depth\": 0})\n",
    "\n",
    "vector_rag_chain = (\n",
    "    {\"context\": vector_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PreparedStatement' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_and_render\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_rag_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQUESTION\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mrun_and_render\u001b[0;34m(chain, question)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_and_render\u001b[39m(chain, question):\n\u001b[0;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     display(Markdown(result))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2393\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2393\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2395\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:3036\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3024\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3025\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3026\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3035\u001b[0m         ]\n\u001b[0;32m-> 3036\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:3036\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3024\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3025\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3026\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3035\u001b[0m         ]\n\u001b[0;32m-> 3036\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2393\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2393\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2395\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/retrievers.py:194\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the retriever to get relevant documents.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03mMain entry point for synchronous retriever invocations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    retriever.invoke(\"query\")\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:148\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     emit_warning()\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/retrievers.py:323\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    322\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    326\u001b[0m         result,\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/agent-framework-aiP65pJh-py3.11/lib/python3.11/site-packages/langchain_core/retrievers.py:316\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 316\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/code/ragstack-ai/libs/knowledge-store/ragstack_knowledge_store/langchain/base.py:439\u001b[0m, in \u001b[0;36mKnowledgeStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    437\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraversal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraversal_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr_traversal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39mmmr_traversal_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs))\n",
      "File \u001b[0;32m~/code/ragstack-ai/libs/knowledge-store/ragstack_knowledge_store/langchain/cassandra.py:143\u001b[0m, in \u001b[0;36mCassandraKnowledgeStore.traversal_search\u001b[0;34m(self, query, k, depth, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraversal_search\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Document]:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraversal_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m Document(\n\u001b[1;32m    145\u001b[0m             page_content\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m    146\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    147\u001b[0m         )\n",
      "File \u001b[0;32m~/code/ragstack-ai/libs/knowledge-store/ragstack_knowledge_store/knowledge_store.py:483\u001b[0m, in \u001b[0;36mKnowledgeStore.traversal_search\u001b[0;34m(self, query, k, depth)\u001b[0m\n\u001b[1;32m    476\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m    477\u001b[0m     cq\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepared_query_ids_by_embedding,\n\u001b[1;32m    479\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m(query_embedding, k),\n\u001b[1;32m    480\u001b[0m         callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m nodes: visit(\u001b[38;5;241m0\u001b[39m, nodes),\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepared_query_by_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvisited\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PreparedStatement' object is not callable"
     ]
    }
   ],
   "source": [
    "run_and_render(vector_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Traversal Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth 1 does vector similarity and then traverses 1 level of edges.\n",
    "graph_retriever = graph_store.as_retriever(search_kwargs={\"depth\": 1})\n",
    "\n",
    "graph_rag_chain = (\n",
    "    {\"context\": graph_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_render(graph_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMR Graph Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_graph_retriever = graph_store.as_retriever(\n",
    "    search_type = \"mmr_traversal\",\n",
    "    search_kwargs = {\n",
    "        \"k\": 4,\n",
    "        \"fetch_k\": 10,\n",
    "        \"depth\": 2,\n",
    "        # \"score_threshold\": 0.2,\n",
    "    },\n",
    ")\n",
    "\n",
    "mmr_graph_rag_chain = (\n",
    "    {\"context\": mmr_graph_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Astra DB Serverless uses the JVector vector search engine for its vector indexing, which employs graph-based indexing algorithms. JVector builds a graph index, adding new documents to the graph immediately, which allows for efficient searches right away. The specific type of graph index used by JVector is in the DiskANN family tree, which is known for its incremental construction and updating capabilities, making it suitable for dynamic datasets.\n",
       "\n",
       "Here are some details about JVector's architecture and the algorithms it uses:\n",
       "\n",
       "1. **Graph-based Index**:\n",
       "   - **Single-layer Graph**: JVector uses a single-layer graph with nonblocking concurrency control, which scales linearly with the number of cores.\n",
       "   - **Two-pass Searches**: JVector supports two-pass searches, where the first pass uses lossily compressed representations of the vectors kept in memory, and the second pass uses more accurate representations read from disk.\n",
       "\n",
       "2. **Compression Techniques**:\n",
       "   - **Product Quantization (PQ)**: JVector can compress vectors using PQ, which helps reduce memory usage and latency while preserving accuracy.\n",
       "   - **Binary Quantization (BQ)**: JVector also supports BQ, although it is generally less useful than PQ for search accuracy.\n",
       "\n",
       "3. **Additional Features**:\n",
       "   - **Anisotropic Weighting**: JVector can use anisotropic weighting with PQ to improve performance.\n",
       "   - **Fused ADC**: PQ codebooks can be transposed and written inline with the graph adjacency list for faster searches.\n",
       "\n",
       "These algorithms and techniques allow JVector to efficiently handle high-dimensional vector spaces, making it well-suited for similarity searches in a vector database like Astra DB Serverless."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_and_render(mmr_graph_rag_chain, QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Retrieval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the question and see what documents each technique retrieves.\n",
    "for i, doc in enumerate(vector_retriever.invoke(QUESTION)):\n",
    "  print(f\"Vector [{i}]:    {doc.metadata['content_id']}\")\n",
    "\n",
    "for i, doc in enumerate(graph_retriever.invoke(QUESTION)):\n",
    "  print(f\"Graph [{i}]:     {doc.metadata['content_id']}\")\n",
    "\n",
    "for i, doc in enumerate(mmr_graph_retriever.invoke(QUESTION)):\n",
    "  print(f\"MMR Graph [{i}]: {doc.metadata['content_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "With vector only we retrieved chunks from the Astra documentation explaining that it used JVector.\n",
    "Since it didn't follow the link to [JVector on GitHub](https://github.com/jbellis/jvector) it didn't actually answer the question.\n",
    "\n",
    "The graph retrieval started with the same set of chunks, but it followed the edge to the documents we loaded from GitHub.\n",
    "This allowed the LLM to read in more depth how JVector is implemented, which allowed it to answer the question more clearly and with more detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-framework-aiP65pJh-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
