"""Base Vector Store module for ColBERT.

This module defines the abstract base class for a standard vector store
specifically designed to work with ColBERT or similar dense embedding models,
and can be used to create a LangChain or LlamaIndex ColBERT vector store.
"""

from __future__ import annotations

from abc import ABC, abstractmethod
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .base_retriever import BaseRetriever
    from .objects import Chunk, Metadata

# LlamaIndex Node (chunk) has ids, text, embedding, metadata
#            VectorStore.add(nodes: List[Node]) -> List[str](ids): embeds texts OUTside add  # noqa: E501
#                       .delete(id)
#                       .query(embedding) -> Nodes, Scores, Ids

# LangChain Document (doc or chunk) has page_content, metadata
#           VectorStore.add(texts: List[str], metadatas: Optional[List[dict]]) -> List[str](ids): embeds texts INside add  # noqa: E501
#                      .delete(ids: List[str]): deletes by id
#                      .search(query: str) -> List[Document]: uses retriever to search in store  # noqa: E501
#                      .as_retriever() -> Retriever


class BaseVectorStore(ABC):
    """Base Vector Store abstract class for ColBERT.

    Abstract base class (ABC) for a storage system designed to hold vector
    representations of text chunks, typically generated by a ColBERT model or similar
    embedding model.

    This class defines the interface for storing and managing the embedded text chunks,
    supporting operations like adding new chunks to the store and deleting existing
    documents by their identifiers.
    """

    # handles LlamaIndex add
    @abstractmethod
    def add_chunks(self, chunks: list[Chunk]) -> list[tuple[str, int]]:
        """Stores a list of embedded text chunks in the vector store.

        Args:
            chunks (List[Chunk]): A list of `Chunk` instances to be stored.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain add
    @abstractmethod
    def add_texts(
        self,
        texts: list[str],
        metadatas: list[Metadata] | None,
        doc_id: str | None = None,
    ) -> list[tuple[str, int]]:
        """Adds text chunks to the vector store.

        Embeds and stores a list of text chunks and optional metadata into the vector
        store.

        Args:
            texts (List[str]): The list of text chunks to be embedded
            metadatas (Optional[List[Metadata]])): An optional list of Metadata to be
                stored. If provided, these are set 1 to 1 with the texts list.
            doc_id (Optional[str]): The document id associated with the texts.
                If not provided, it is generated.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain and LlamaIndex delete
    @abstractmethod
    def delete_chunks(self, doc_ids: list[str]) -> bool:
        """Deletes chunks from the vector store based on their document id.

        Args:
            doc_ids (List[str]): A list of document identifiers specifying the chunks
                to be deleted.

        Returns:
            True if the all the deletes were successful.
        """

    # handles LlamaIndex add
    @abstractmethod
    async def aadd_chunks(
        self, chunks: list[Chunk], concurrent_inserts: int = 100
    ) -> list[tuple[str, int]]:
        """Stores a list of embedded text chunks in the vector store.

        Args:
            chunks: A list of `Chunk` instances to be stored.
            concurrent_inserts: How many concurrent inserts to make to
                the database. Defaults to 100.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain add
    @abstractmethod
    async def aadd_texts(
        self,
        texts: list[str],
        metadatas: list[Metadata] | None,
        doc_id: str | None = None,
        concurrent_inserts: int = 100,
    ) -> list[tuple[str, int]]:
        """Adds text chunks to the vector store.

        Embeds and stores a list of text chunks and optional metadata into the vector
        store.

        Args:
            texts: The list of text chunks to be embedded
            metadatas: An optional list of Metadata to be
                stored. If provided, these are set 1 to 1 with the texts list.
            doc_id: The document id associated with the texts.
                If not provided, it is generated.
            concurrent_inserts: How many concurrent inserts to make to
                the database. Defaults to 100.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain and LlamaIndex delete
    @abstractmethod
    async def adelete_chunks(
        self, doc_ids: list[str], concurrent_deletes: int = 100
    ) -> bool:
        """Deletes chunks from the vector store based on their document id.

        Args:
            doc_ids: A list of document identifiers specifying the chunks
                to be deleted.
            concurrent_deletes: How many concurrent deletes to make to
                the database. Defaults to 100.

        Returns:
            True if the all the deletes were successful.
        """

    # handles LangChain as_retriever
    @abstractmethod
    def as_retriever(self) -> BaseRetriever:
        """Gets a retriever using the vector store."""
