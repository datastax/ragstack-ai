"""
This module defines the abstract base class for a standard vector store
specifically designed to work with ColBERT or similar dense embedding models,
and can be used to create a LangChain or LlamaIndex ColBERT vector store.
"""

from abc import ABC, abstractmethod
from typing import List, Optional, Tuple

from .base_retriever import BaseRetriever
from .objects import Chunk, Metadata

# LlamaIndex Node (chunk) has ids, text, embedding, metadata
#            VectorStore.add(nodes: List[Node]) -> List[str](ids): embeds texts OUTside add
#                       .delete(id)
#                       .query(embedding) -> Nodes, Scores, Ids

# LangChain Document (doc or chunk) has page_content, metadata
#           VectorStore.add(texts: List[str], metadatas: Optional[List[dict]]) -> List[str](ids): embeds texts INside add
#                      .delete(ids: List[str]): deletes by id
#                      .search(query: str) -> List[Document]: uses retriever to search in store
#                      .as_retriever() -> Retriever


class BaseVectorStore(ABC):
    """
    Abstract base class (ABC) for a storage system designed to hold vector representations of text chunks,
    typically generated by a ColBERT model or similar embedding model.

    This class defines the interface for storing and managing the embedded text chunks, supporting
    operations like adding new chunks to the store and deleting existing documents by their identifiers.
    """

    # handles LlamaIndex add
    @abstractmethod
    def add_chunks(self, chunks: List[Chunk]) -> List[Tuple[str, int]]:
        """
        Stores a list of embedded text chunks in the vector store

        Parameters:
            chunks (List[Chunk]): A list of `Chunk` instances to be stored.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain add
    @abstractmethod
    def add_texts(
        self,
        texts: List[str],
        metadatas: Optional[List[Metadata]],
        doc_id: Optional[str] = None,
    ) -> List[Tuple[str, int]]:
        """
        Embeds and stores a list of text chunks and optional metadata into the vector store

        Parameters:
            texts (List[str]): The list of text chunks to be embedded
            metadatas (Optional[List[Metadata]])): An optional list of Metadata to be stored.
                                                   If provided, these are set 1 to 1 with the texts list.
            doc_id (Optional[str]): The document id associated with the texts. If not provided,
                                    it is generated.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain and LlamaIndex delete
    @abstractmethod
    def delete_chunks(self, doc_ids: List[str]) -> bool:
        """
        Deletes chunks from the vector store based on their document id.

        Parameters:
            doc_ids (List[str]): A list of document identifiers specifying the chunks to be deleted.

        Returns:
            True if the all the deletes were successful.
        """

    # handles LlamaIndex add
    @abstractmethod
    async def aadd_chunks(self, chunks: List[Chunk], concurrent_inserts: Optional[int] = 100) -> List[Tuple[str, int]]:
        """
        Stores a list of embedded text chunks in the vector store

        Parameters:
            chunks (List[Chunk]): A list of `Chunk` instances to be stored.
            concurrent_inserts (Optional[int]): How many concurrent inserts to make to the database. Defaults to 100.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain add
    @abstractmethod
    async def aadd_texts(
        self,
        texts: List[str],
        metadatas: Optional[List[Metadata]],
        doc_id: Optional[str] = None,
        concurrent_inserts: Optional[int] = 100,
    ) -> List[Tuple[str, int]]:
        """
        Embeds and stores a list of text chunks and optional metadata into the vector store

        Parameters:
            texts (List[str]): The list of text chunks to be embedded
            metadatas (Optional[List[Metadata]])): An optional list of Metadata to be stored.
                                                   If provided, these are set 1 to 1 with the texts list.
            doc_id (Optional[str]): The document id associated with the texts. If not provided,
                                    it is generated.
            concurrent_inserts (Optional[int]): How many concurrent inserts to make to the database. Defaults to 100.

        Returns:
            a list of tuples: (doc_id, chunk_id)
        """

    # handles LangChain and LlamaIndex delete
    @abstractmethod
    async def adelete_chunks(self, doc_ids: List[str], concurrent_deletes: Optional[int] = 100) -> bool:
        """
        Deletes chunks from the vector store based on their document id.

        Parameters:
            doc_ids (List[str]): A list of document identifiers specifying the chunks to be deleted.
            concurrent_deletes (Optional[int]): How many concurrent deletes to make to the database. Defaults to 100.

        Returns:
            True if the all the deletes were successful.
        """

    # handles LangChain as_retriever
    @abstractmethod
    def as_retriever(self) -> BaseRetriever:
        """
        Gets a retriever using the vector store.
        """
