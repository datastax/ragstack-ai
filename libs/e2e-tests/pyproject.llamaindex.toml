[tool.poetry]
name = "ragstack-e2e-tests"
version = "0.1.0"
description = "RAGStack tests"
license = ""
authors = ["DataStax"]

[tool.poetry.dependencies]
python = ">=3.9,<3.13,!=3.9.7"

[tool.poetry.group.test.dependencies]
ragstack-ai-tests-utils = { path = "../tests-utils", develop = true }
black = "*"
ruff = "*"
azure-storage-blob = "^12.19.0"
pillow = "^10.2.0"
python-dotenv = "^1.0.1"
trulens-eval = "^0.31.0"
langchainhub = "^0.1.15"

# Temporarily use nemoguardrails HEAD to get https://github.com/NVIDIA/NeMo-Guardrails/pull/551
# nemoguardrails = "^0.8.0"
nemoguardrails = { git = "https://github.com/NVIDIA/NeMo-Guardrails.git", branch = "develop" }


# From LangChain optional deps, needed by WebBaseLoader
beautifulsoup4 = "^4"

llama-index = { git = "https://github.com/run-llama/llama_index.git", branch = "main" }
llama-index-core = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-core" }
llama-index-readers-llama-parse = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/readers/llama-index-readers-llama-parse" }
llama-index-embeddings-langchain = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/embeddings/llama-index-embeddings-langchain" }
llama-index-vector-stores-astra-db = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/vector_stores/llama-index-vector-stores-astra-db" }
llama-index-vector-stores-cassandra = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/vector_stores/llama-index-vector-stores-cassandra" }
llama-index-tools-cassandra = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/tools/llama-index-tools-cassandra" }
llama-index-llms-bedrock = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/llms/llama-index-llms-bedrock" }
llama-index-llms-azure-openai = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/llms/llama-index-llms-azure-openai" }
llama-index-llms-gemini = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/llms/llama-index-llms-gemini" }
llama-index-llms-vertex = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/llms/llama-index-llms-vertex" }
llama-index-embeddings-bedrock = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/embeddings/llama-index-embeddings-bedrock" }
llama-index-embeddings-azure-openai = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/embeddings/llama-index-embeddings-azure-openai" }
llama-index-embeddings-gemini = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/embeddings/llama-index-embeddings-gemini" }
llama-index-multi-modal-llms-gemini = { git = "https://github.com/run-llama/llama_index.git", branch = "main", subdirectory = "llama-index-integrations/multi_modal_llms/llama-index-multi-modal-llms-gemini" }

llama-parse = { git = "https://github.com/run-llama/llama_parse.git", branch = "main" }

langchain = "0.2.5"
langchain-core = "0.2.9"
langchain-community = "0.2.5"
langchain-astradb = "0.3.3"
langchain-openai = "0.1.8"
langchain-google-genai = { version = "1.0.6" }
langchain-google-vertexai = { version = "1.0.5" }
langchain-nvidia-ai-endpoints = { version = "0.1.1" }

unstructured = "0.14.5"

[tool.poetry.group.dev.dependencies]
setuptools = "^70.0.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
